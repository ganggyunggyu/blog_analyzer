#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MongoDB ë°ì´í„° ìˆ˜ì§‘ê¸°
ëª¨ë“  ë¸”ë¡œê·¸ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ì— ëª¨ì•„ì„œ Claudeê°€ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì €ì¥
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

try:
    from mongodb_service import MongoDBService
    from utils.get_category_db_name import get_category_db_name

    MONGODB_AVAILABLE = True
except ImportError:
    MONGODB_AVAILABLE = False
    print("MongoDB ê´€ë ¨ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")


class BlogDataCollector:
    """ë¸”ë¡œê·¸ ë°ì´í„° ìˆ˜ì§‘ ë° ì •ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self.db_service = None
        if MONGODB_AVAILABLE:
            try:
                self.db_service = MongoDBService()
            except Exception as e:
                print(f"MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
                self.db_service = None

    def get_available_databases(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ë°˜í™˜"""
        if not self.db_service:
            return ["demo_wedding", "demo_diet", "demo_ophthalmology"]

        try:
            # MongoDB í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            db_names = self.db_service.client.list_database_names()
            # ì‹œìŠ¤í…œ ë°ì´í„°ë² ì´ìŠ¤ ì œì™¸
            user_dbs = [db for db in db_names if db not in ["admin", "local", "config"]]
            return user_dbs
        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def collect_database_data(self, db_name: str) -> Dict[str, Any]:
        """íŠ¹ì • ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘"""
        if not self.db_service:
            return self._get_demo_data(db_name)

        try:
            # ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½
            self.db_service.set_db_name(db_name)

            # ëª¨ë“  ë¶„ì„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            analysis_data = self.db_service.get_latest_analysis_data()

            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            collection_stats = {}
            collections = [
                "morphemes",
                "sentences",
                "expressions",
                "parameters",
                "subtitles",
                "templates",
            ]

            for collection in collections:
                try:
                    count = self.db_service.db[collection].count_documents({})
                    collection_stats[collection] = count
                except Exception as e:
                    collection_stats[collection] = f"ì˜¤ë¥˜: {e}"

            return {
                "database_name": db_name,
                "collection_stats": collection_stats,
                "analysis_data": analysis_data,
                "collected_at": datetime.now().isoformat(),
            }

        except Exception as e:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ {db_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {"database_name": db_name, "error": str(e)}

    def _get_demo_data(self, db_name: str) -> Dict[str, Any]:
        """ë°ëª¨ ë°ì´í„° ìƒì„±"""
        demo_data = {
            "database_name": db_name,
            "collection_stats": {
                "morphemes": 100,
                "sentences": 50,
                "expressions": 30,
                "parameters": 25,
                "subtitles": 15,
                "templates": 5,
            },
            "analysis_data": {
                "unique_words": ["ì œí’ˆ", "ì‚¬ìš©", "íš¨ê³¼", "ë§Œì¡±", "ì¶”ì²œ"],
                "sentences": [
                    "ì •ë§ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì œí’ˆì´ì—ˆì–´ìš”",
                    "ì‚¬ìš©í•´ë³´ë‹ˆ íš¨ê³¼ê°€ í™•ì‹¤í•˜ë”ë¼êµ¬ìš”",
                    "ê°€ê²©ëŒ€ë¹„ ì„±ëŠ¥ì´ ì¢‹ì•˜ìŠµë‹ˆë‹¤",
                ],
                "expressions": {
                    "ê¸ì •í‘œí˜„": ["ë§Œì¡±ìŠ¤ëŸ¬ì› ì–´ìš”", "íš¨ê³¼ì ì´ì—ˆì–´ìš”", "ì¢‹ë”ë¼êµ¬ìš”"],
                    "ë¶€ì •í‘œí˜„": ["ì•„ì‰¬ì› ë˜ ì ", "ë¶ˆí¸í–ˆë˜ ë¶€ë¶„", "ê°œì„  í•„ìš”í•œ"],
                    "ê²½í—˜í‘œí˜„": ["ì‹¤ì œë¡œ ì¨ë³´ë‹ˆ", "ê°œì¸ì ìœ¼ë¡œ ëŠë‚€", "ì§ì ‘ ê²½í—˜í•œ"],
                },
                "parameters": {
                    "ê°€ê²©": ["ì•½ 30ë§Œì›", "50ë§Œì›ëŒ€", "100ë§Œì› ì´ìƒ"],
                    "ì‹œê°„": ["3ê°œì›”", "6ê°œì›”", "1ë…„ê°„"],
                    "íš¨ê³¼": ["30% ê°œì„ ", "í™•ì‹¤í•œ ë³€í™”", "ëˆˆì— ë„ëŠ” íš¨ê³¼"],
                },
                "subtitles": [
                    "ì œí’ˆ ì„ íƒì˜ ì´ìœ ì™€ ê³ ë¯¼",
                    "ê°€ê²©ê³¼ ì„±ëŠ¥ ê·¸ë¦¬ê³  íŠ¹ì§•",
                    "ì‹¤ì œ ì‚¬ìš©í•´ë³¸ ì†”ì§í•œ í›„ê¸°",
                    "ì¥ì ê³¼ ë‹¨ì  ë¹„êµ ë¶„ì„",
                    "í™œìš© íŒê³¼ ì¢…í•© í‰ê°€",
                ],
                "templates": [
                    {
                        "file_name": f"sample_{db_name}_1.txt",
                        "templated_text": "ì•ˆë…•í•˜ì„¸ìš” ì˜¤ëŠ˜ì€ ì œí’ˆ í›„ê¸°ë¥¼ ê³µìœ í•´ë“œë¦¬ë ¤ê³  í•´ìš”...",
                    }
                ],
            },
            "collected_at": datetime.now().isoformat(),
        }
        return demo_data

    def collect_all_databases(self) -> Dict[str, Any]:
        """ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = {
            "collection_info": {
                "collected_at": datetime.now().isoformat(),
                "collector_version": "1.0",
                "mongodb_available": MONGODB_AVAILABLE,
            },
            "databases": {},
        }

        db_names = self.get_available_databases()
        print(f"ìˆ˜ì§‘í•  ë°ì´í„°ë² ì´ìŠ¤: {db_names}")

        for db_name in db_names:
            print(f"ë°ì´í„°ë² ì´ìŠ¤ ìˆ˜ì§‘ ì¤‘: {db_name}")
            db_data = self.collect_database_data(db_name)
            all_data["databases"][db_name] = db_data

        return all_data

    def format_for_claude(self, all_data: Dict[str, Any]) -> str:
        """Claudeê°€ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ í˜•íƒœë¡œ í¬ë§·íŒ…"""

        output_lines = []

        # í—¤ë”
        output_lines.append("=" * 80)
        output_lines.append("ë¸”ë¡œê·¸ ë°ì´í„° ì»¬ë ‰ì…˜")
        output_lines.append("=" * 80)
        output_lines.append("")

        # ìˆ˜ì§‘ ì •ë³´
        collection_info = all_data.get("collection_info", {})
        output_lines.append(
            f"ìˆ˜ì§‘ ì‹œê°„: {collection_info.get('collected_at', 'Unknown')}"
        )
        output_lines.append(
            f"MongoDB ì—°ê²°: {'ì„±ê³µ' if collection_info.get('mongodb_available') else 'ì‹¤íŒ¨ (ë°ëª¨ ë°ì´í„°)'}"
        )
        output_lines.append(f"ì´ ë°ì´í„°ë² ì´ìŠ¤ ìˆ˜: {len(all_data.get('databases', {}))}")
        output_lines.append("")

        # ê° ë°ì´í„°ë² ì´ìŠ¤ë³„ ë°ì´í„°
        for db_name, db_data in all_data.get("databases", {}).items():
            output_lines.append("-" * 50)
            output_lines.append(f"ë°ì´í„°ë² ì´ìŠ¤: {db_name}")
            output_lines.append("-" * 50)
            output_lines.append("")

            # ì»¬ë ‰ì…˜ í†µê³„
            if "collection_stats" in db_data:
                output_lines.append("ğŸ“Š ì»¬ë ‰ì…˜ í†µê³„:")
                for collection, count in db_data["collection_stats"].items():
                    output_lines.append(f"  - {collection}: {count}ê°œ")
                output_lines.append("")

            # ë¶„ì„ ë°ì´í„°
            analysis_data = db_data.get("analysis_data", {})

            # ê³ ìœ  ë‹¨ì–´
            unique_words = analysis_data.get("unique_words", [])
            if unique_words:
                output_lines.append("ğŸ“ ê³ ìœ  ë‹¨ì–´ (ìƒìœ„ 20ê°œ):")
                for word in unique_words[:20]:
                    output_lines.append(f"  - {word}")
                output_lines.append("")

            # ë¬¸ì¥ ì˜ˆì‹œ
            sentences = analysis_data.get("sentences", [])
            if sentences:
                output_lines.append("ğŸ’¬ ë¬¸ì¥ ì˜ˆì‹œ (ìƒìœ„ 10ê°œ):")
                for i, sentence in enumerate(sentences[:10], 1):
                    output_lines.append(f"  {i}. {sentence}")
                output_lines.append("")

            # í‘œí˜„ ë¼ì´ë¸ŒëŸ¬ë¦¬
            expressions = analysis_data.get("expressions", {})
            if expressions:
                output_lines.append("ğŸ­ í‘œí˜„ ë¼ì´ë¸ŒëŸ¬ë¦¬:")
                for category, expr_list in expressions.items():
                    output_lines.append(f"  [{category}]")
                    for expr in expr_list[:5]:  # ìƒìœ„ 5ê°œë§Œ
                        output_lines.append(f"    - {expr}")
                output_lines.append("")

            # íŒŒë¼ë¯¸í„°
            parameters = analysis_data.get("parameters", {})
            if parameters:
                output_lines.append("âš™ï¸ íŒŒë¼ë¯¸í„°:")
                for category, param_list in parameters.items():
                    output_lines.append(f"  [{category}]")
                    for param in param_list[:5]:  # ìƒìœ„ 5ê°œë§Œ
                        output_lines.append(f"    - {param}")
                output_lines.append("")

            # ë¶€ì œëª©
            subtitles = analysis_data.get("subtitles", [])
            if subtitles:
                output_lines.append("ğŸ“‹ ë¶€ì œëª© ì˜ˆì‹œ:")
                for subtitle in subtitles[:10]:
                    output_lines.append(f"  - {subtitle}")
                output_lines.append("")

            # í…œí”Œë¦¿
            templates = analysis_data.get("templates", [])
            if templates:
                output_lines.append("ğŸ“„ í…œí”Œë¦¿ ì˜ˆì‹œ:")
                for i, template in enumerate(templates[:3], 1):
                    file_name = template.get("file_name", "Unknown")
                    content = template.get("templated_text", "")
                    output_lines.append(f"  {i}. {file_name}")
                    output_lines.append(f"     {content[:100]}...")  # ì²« 100ìë§Œ
                output_lines.append("")

            output_lines.append("")

        return "\n".join(output_lines)

    def save_data(self, data: Dict[str, Any], format_type: str = "both") -> List[str]:
        """ë°ì´í„° ì €ì¥ (JSON, í…ìŠ¤íŠ¸, ë˜ëŠ” ë‘˜ ë‹¤)"""
        saved_files = []
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # claude í´ë” ë‚´ì— data ì„œë¸Œí´ë” ìƒì„±
        data_dir = Path(__file__).parent / "data"
        data_dir.mkdir(exist_ok=True)

        if format_type in ["json", "both"]:
            # JSON í˜•íƒœë¡œ ì €ì¥
            json_file = data_dir / f"blog_data_{timestamp}.json"
            with open(json_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            saved_files.append(str(json_file))
            print(f"JSON íŒŒì¼ ì €ì¥: {json_file}")

        if format_type in ["text", "both"]:
            # í…ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥
            text_file = data_dir / f"blog_data_{timestamp}.txt"
            formatted_text = self.format_for_claude(data)
            with open(text_file, "w", encoding="utf-8") as f:
                f.write(formatted_text)
            saved_files.append(str(text_file))
            print(f"í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥: {text_file}")

        return saved_files


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("MongoDB ë¸”ë¡œê·¸ ë°ì´í„° ìˆ˜ì§‘ê¸°")
    print("=" * 60)

    collector = BlogDataCollector()

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
    databases = collector.get_available_databases()
    print(f"ë°œê²¬ëœ ë°ì´í„°ë² ì´ìŠ¤: {databases}")

    if not databases:
        print("ìˆ˜ì§‘í•  ë°ì´í„°ë² ì´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ëª¨ë“  ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
    print("\në°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
    all_data = collector.collect_all_databases()

    # íŒŒì¼ë¡œ ì €ì¥
    print("\níŒŒì¼ ì €ì¥ ì¤‘...")
    saved_files = collector.save_data(all_data, format_type="both")

    print(f"\nâœ… ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
    print(f"ì €ì¥ëœ íŒŒì¼: {saved_files}")

    # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
    total_dbs = len(all_data.get("databases", {}))
    print(f"ğŸ“Š ì´ {total_dbs}ê°œ ë°ì´í„°ë² ì´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")


if __name__ == "__main__":
    main()
