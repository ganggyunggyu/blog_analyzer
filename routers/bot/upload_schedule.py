"""ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ë°œí–‰ API - ZIP ì—…ë¡œë“œ + ì˜ˆì•½ë°œí–‰"""

import zipfile
from datetime import datetime
from pathlib import Path
from tempfile import NamedTemporaryFile
from typing import Optional

from fastapi import APIRouter, UploadFile, File, Form, HTTPException
from fastapi.responses import JSONResponse

from routers.auth.naver import naver_login_with_playwright
from routers.generate.batch import generate_batch_id
from utils.logger import log

from .common import (
    PENDING_DIR,
    create_queue,
    get_queue_manuscripts,
    update_queue_status,
    cleanup_empty_queue,
    publish_manuscripts_batch,
)
from .auto_schedule import calculate_schedule, build_schedule_times

router = APIRouter()


@router.post("/upload-schedule")
async def upload_schedule_bot(
    file: UploadFile = File(...),
    account_id: str = Form(...),
    password: str = Form(...),
    start_date: str = Form(...),
    start_hour: int = Form(10),
    posts_per_day: int = Form(3),
    interval_hours: int = Form(2),
    delay_between_posts: int = Form(10),
):
    """ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ë°œí–‰: ZIP ì—…ë¡œë“œ + ì˜ˆì•½ë°œí–‰

    ì›ê³ ë¥¼ ZIPìœ¼ë¡œ ì—…ë¡œë“œí•˜ê³  ìŠ¤ì¼€ì¤„ì— ë§ì¶° ì˜ˆì•½ ë°œí–‰í•©ë‹ˆë‹¤.

    Args:
        file: ZIP íŒŒì¼ (ì›ê³ ë“¤)
        account_id: ë„¤ì´ë²„ ê³„ì • ID
        password: ë„¤ì´ë²„ ê³„ì • ë¹„ë°€ë²ˆí˜¸
        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        start_hour: ì‹œì‘ ì‹œê°„ (0-23, ê¸°ë³¸: 10)
        posts_per_day: í•˜ë£¨ ë°œí–‰ ìˆ˜ (1-10, ê¸°ë³¸: 3)
        interval_hours: ë°œí–‰ ê°„ê²© (1-12ì‹œê°„, ê¸°ë³¸: 2)
        delay_between_posts: ë°œí–‰ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ, ê¸°ë³¸: 10)

    ZIP êµ¬ì¡°:
        upload.zip
        â”œâ”€â”€ í‚¤ì›Œë“œ1/
        â”‚   â”œâ”€â”€ í‚¤ì›Œë“œ1.txt (ì²« ì¤„=ì œëª©, ë‚˜ë¨¸ì§€=ë³¸ë¬¸)
        â”‚   â””â”€â”€ 1.png, 2.png ... (ì´ë¯¸ì§€)
        â””â”€â”€ í‚¤ì›Œë“œ2/
            â””â”€â”€ ...
    """
    # ìœ íš¨ì„± ê²€ì‚¬
    if not file.filename or not file.filename.endswith(".zip"):
        raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    if not 0 <= start_hour <= 23:
        raise HTTPException(status_code=400, detail="ì‹œì‘ ì‹œê°„ì€ 0-23 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    if not 1 <= posts_per_day <= 10:
        raise HTTPException(status_code=400, detail="í•˜ë£¨ ë°œí–‰ ìˆ˜ëŠ” 1-10 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    if not 1 <= interval_hours <= 12:
        raise HTTPException(status_code=400, detail="ë°œí–‰ ê°„ê²©ì€ 1-12ì‹œê°„ ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    start_ts = datetime.now()

    log.header("ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ë°œí–‰ ì‹œì‘", "ğŸ“¦")
    log.kv("ê³„ì •", f"{account_id[:3]}***")
    log.kv("íŒŒì¼", file.filename)
    log.kv("ì‹œì‘ì¼", start_date)
    log.kv("ì‹œì‘ì‹œê°„", f"{start_hour}:00")
    log.kv("ì„¤ì •", f"í•˜ë£¨ {posts_per_day}ê°œ / {interval_hours}ì‹œê°„ ê°„ê²©")

    # ========== 1ë‹¨ê³„: ZIP ì—…ë¡œë“œ ==========
    log.header("1ë‹¨ê³„: ZIP ì—…ë¡œë“œ", "ğŸ“¤")

    batch_id = generate_batch_id()
    log.kv("ë°°ì¹˜ ID", batch_id)

    # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
    with NamedTemporaryFile(delete=False, suffix=".zip") as tmp:
        content = await file.read()
        tmp.write(content)
        tmp_path = Path(tmp.name)

    uploaded = []
    keywords = []
    upload_idx = 0

    try:
        with zipfile.ZipFile(tmp_path, "r") as zf:
            # ZIP ë‚´ ìµœìƒìœ„ í´ë”ë“¤ ì¶”ì¶œ
            top_folders = set()
            for name in zf.namelist():
                parts = name.split("/")
                if len(parts) > 1 and parts[0]:
                    top_folders.add(parts[0])

            log.kv("í´ë” ìˆ˜", len(top_folders))

            for folder_name in sorted(top_folders):
                # ì‹œìŠ¤í…œ í´ë” ë¬´ì‹œ
                if folder_name.startswith("__") or folder_name.startswith("."):
                    continue

                upload_idx += 1
                new_folder_name = f"{batch_id}_{str(upload_idx).zfill(4)}"
                dst_dir = PENDING_DIR / new_folder_name
                dst_dir.mkdir(parents=True, exist_ok=True)

                # í•´ë‹¹ í´ë” ë‚´ íŒŒì¼ë“¤ ì¶”ì¶œ
                for name in zf.namelist():
                    if not name.startswith(folder_name + "/"):
                        continue

                    rel_path = name[len(folder_name) + 1:]
                    if not rel_path or rel_path.endswith("/"):
                        continue

                    target_path = dst_dir / rel_path
                    target_path.parent.mkdir(parents=True, exist_ok=True)

                    with zf.open(name) as src:
                        with open(target_path, "wb") as dst:
                            dst.write(src.read())

                uploaded.append({
                    "id": new_folder_name,
                    "keyword": folder_name,
                })
                keywords.append(folder_name)
                log.debug(f"ì—…ë¡œë“œ: {folder_name} â†’ {new_folder_name}")

    except zipfile.BadZipFile:
        raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ZIP íŒŒì¼ì…ë‹ˆë‹¤.")
    finally:
        tmp_path.unlink(missing_ok=True)

    if not uploaded:
        raise HTTPException(status_code=400, detail="ZIP íŒŒì¼ì— ì›ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    log.success("ì—…ë¡œë“œ ì™„ë£Œ", count=len(uploaded))

    # ========== 2ë‹¨ê³„: ìŠ¤ì¼€ì¤„ ê³„ì‚° ==========
    log.header("2ë‹¨ê³„: ìŠ¤ì¼€ì¤„ ê³„ì‚°", "ğŸ—“ï¸")

    schedule = calculate_schedule(
        start_date=start_date,
        start_hour=start_hour,
        keywords=keywords,
        posts_per_day=posts_per_day,
        interval_hours=interval_hours,
    )

    total_days = (len(keywords) + posts_per_day - 1) // posts_per_day

    log.kv("ì´ ì¼ìˆ˜", f"{total_days}ì¼")
    log.kv("ì´ ìŠ¤ì¼€ì¤„", f"{len(schedule)}ê°œ")

    # ========== 3ë‹¨ê³„: í ìƒì„± ==========
    log.header("3ë‹¨ê³„: í ìƒì„±", "ğŸ“¦")

    queue_id, queue_dir = create_queue(
        manuscript_ids=[item["id"] for item in uploaded],
        account_id=account_id,
        schedule_date=start_date,
    )

    manuscripts = get_queue_manuscripts(queue_id)
    log.kv("í ID", queue_id)
    log.kv("ì›ê³  ìˆ˜", len(manuscripts))

    # ========== 4ë‹¨ê³„: ë¡œê·¸ì¸ ==========
    log.header("4ë‹¨ê³„: ë„¤ì´ë²„ ë¡œê·¸ì¸", "ğŸ”")
    update_queue_status(queue_id, "processing")

    login_result = await naver_login_with_playwright(
        account_id=account_id,
        password=password,
        debug=True,
    )

    if not login_result["success"]:
        update_queue_status(queue_id, "failed")
        raise HTTPException(status_code=401, detail=f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_result.get('message')}")

    cookies = login_result["cookies"]
    log.success("ë¡œê·¸ì¸ ì„±ê³µ", cookies=len(cookies))

    # ========== 5ë‹¨ê³„: ì˜ˆì•½ë°œí–‰ ==========
    log.header("5ë‹¨ê³„: ìŠ¤ì¼€ì¤„ ì˜ˆì•½ë°œí–‰", "ğŸ“¤")

    schedule_times = build_schedule_times(uploaded, schedule)

    publish_results = await publish_manuscripts_batch(
        cookies=cookies,
        queue_dir=queue_dir,
        manuscripts=manuscripts,
        schedule_times=schedule_times,
        account_id=account_id,
        delay=delay_between_posts,
    )

    # ê²°ê³¼ì— day/slot ì •ë³´ ì¶”ê°€
    keyword_to_schedule = {item["keyword"]: item for item in schedule}
    for idx, result in enumerate(publish_results):
        upload_item = uploaded[idx] if idx < len(uploaded) else None
        if upload_item and upload_item["keyword"] in keyword_to_schedule:
            sched = keyword_to_schedule[upload_item["keyword"]]
            result["day"] = sched["day"]
            result["slot"] = sched["slot"]
            result["scheduled_at"] = sched["schedule_time"].isoformat()

    # ========== ê²°ê³¼ ==========
    success_count = sum(1 for r in publish_results if r["success"])
    cleanup_empty_queue(queue_id)

    elapsed = (datetime.now() - start_ts).total_seconds()

    log.divider()
    log.success(
        "ì—…ë¡œë“œ ìŠ¤ì¼€ì¤„ ë°œí–‰ ì™„ë£Œ",
        queue_id=queue_id,
        ì„±ê³µ=f"{success_count}/{len(manuscripts)}",
        ì‹œê°„=f"{elapsed:.0f}s"
    )

    # ì¼ë³„ ìš”ì•½ ìƒì„±
    daily_summary = {}
    for r in publish_results:
        day = r.get("day", 0)
        if day not in daily_summary:
            daily_summary[day] = {"success": 0, "failed": 0}
        if r["success"]:
            daily_summary[day]["success"] += 1
        else:
            daily_summary[day]["failed"] += 1

    return JSONResponse(content={
        "success": True,
        "queue_id": queue_id,
        "batch_id": batch_id,
        "account": f"{account_id[:3]}***",
        "schedule": {
            "start_date": start_date,
            "start_hour": start_hour,
            "days": total_days,
            "posts_per_day": posts_per_day,
            "interval_hours": interval_hours,
        },
        "summary": {
            "uploaded": len(uploaded),
            "published": success_count,
            "failed": len(manuscripts) - success_count,
            "elapsed": round(elapsed, 1),
        },
        "daily_summary": daily_summary,
        "results": publish_results,
    })
