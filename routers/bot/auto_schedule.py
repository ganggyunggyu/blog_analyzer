"""ìë™ ìŠ¤ì¼€ì¤„ ë°œí–‰ API - ì›ê³  ìë™ìƒì„± + ì˜ˆì•½ë°œí–‰ (ë°°ì¹˜ í ì§€ì›)"""

import asyncio
from datetime import datetime, timedelta
from typing import Optional

from fastapi import APIRouter, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel, field_validator

from routers.auth.naver import naver_login_with_playwright
from utils.logger import log

from .common import (
    create_queue,
    get_queue_manuscripts,
    update_queue_status,
    cleanup_empty_queue,
    generate_manuscripts_batch,
    publish_manuscripts_batch,
)

router = APIRouter()


# ========== ìŠ¤í‚¤ë§ˆ ==========

class QueueItem(BaseModel):
    """í ì•„ì´í…œ (ê³„ì • 1ê°œ ë‹¨ìœ„)"""
    account: dict  # {"id": "...", "password": "..."}
    keywords: list[str]  # ìµœì†Œ 1ê°œ

    # ê°œë³„ ì˜¤ë²„ë¼ì´ë“œ (ì„ íƒ)
    service: Optional[str] = None
    ref: Optional[str] = None
    posts_per_day: Optional[int] = None
    interval_hours: Optional[int] = None

    @field_validator("keywords")
    @classmethod
    def validate_keywords(cls, v):
        if len(v) < 1:
            raise ValueError("í‚¤ì›Œë“œëŠ” ìµœì†Œ 1ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
        return v


class AutoScheduleRequest(BaseModel):
    """ìë™ ìŠ¤ì¼€ì¤„ ë°œí–‰ ìš”ì²­ ìŠ¤í‚¤ë§ˆ (ë°°ì—´ ì§€ì›)"""
    queues: list[QueueItem]  # ë°°ì—´ë¡œ ë°›ìŒ

    # ê³µí†µ ìŠ¤ì¼€ì¤„ ì„¤ì •
    start_date: str  # "2025-01-01" í˜•ì‹
    start_hour: int = 10  # ì‹œì‘ ì‹œê°„ (0-23)
    posts_per_day: int = 3  # í•˜ë£¨ ë°œí–‰ ìˆ˜
    interval_hours: int = 2  # ë°œí–‰ ê°„ê²© (ì‹œê°„)

    # ê³µí†µ ìƒì„± ì˜µì…˜
    service: str = "default"
    ref: str = ""
    generate_images: bool = True
    image_count: int = 5

    # ì‹¤í–‰ ì˜µì…˜
    delay_between_posts: int = 10  # ë°œí–‰ ê°„ ë”œë ˆì´ (ì´ˆ)
    delay_between_queues: int = 60  # í ê°„ ë”œë ˆì´ (ì´ˆ)

    @field_validator("queues")
    @classmethod
    def validate_queues(cls, v):
        if len(v) < 1:
            raise ValueError("queuesëŠ” ìµœì†Œ 1ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
        return v

    @field_validator("start_hour")
    @classmethod
    def validate_start_hour(cls, v):
        if not 0 <= v <= 23:
            raise ValueError("ì‹œì‘ ì‹œê°„ì€ 0-23 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return v

    @field_validator("posts_per_day")
    @classmethod
    def validate_posts_per_day(cls, v):
        if not 1 <= v <= 10:
            raise ValueError("í•˜ë£¨ ë°œí–‰ ìˆ˜ëŠ” 1-10 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return v

    @field_validator("interval_hours")
    @classmethod
    def validate_interval_hours(cls, v):
        if not 1 <= v <= 12:
            raise ValueError("ë°œí–‰ ê°„ê²©ì€ 1-12ì‹œê°„ ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
        return v


# ========== ìŠ¤ì¼€ì¤„ ê³„ì‚° ==========

def calculate_schedule(
    start_date: str,
    start_hour: int,
    keywords: list[str],
    posts_per_day: int = 3,
    interval_hours: int = 2,
) -> list[dict]:
    """ë°œí–‰ ìŠ¤ì¼€ì¤„ ê³„ì‚° (í‚¤ì›Œë“œ ê°œìˆ˜ì— ë”°ë¼ ì¼ìˆ˜ ìë™ ê³„ì‚°)"""
    base_date = datetime.strptime(start_date, "%Y-%m-%d")
    base_time = base_date.replace(hour=start_hour, minute=0, second=0, microsecond=0)

    total_days = (len(keywords) + posts_per_day - 1) // posts_per_day
    schedule = []
    keyword_idx = 0

    for day in range(total_days):
        day_base = base_time + timedelta(days=day)

        for slot in range(posts_per_day):
            if keyword_idx >= len(keywords):
                break

            schedule_time = day_base + timedelta(hours=slot * interval_hours)

            schedule.append({
                "keyword": keywords[keyword_idx],
                "schedule_time": schedule_time,
                "day": day + 1,
                "slot": slot + 1,
            })
            keyword_idx += 1

    return schedule


def build_schedule_times(
    generated_ids: list[dict],
    schedule: list[dict],
) -> list[Optional[datetime]]:
    """ìƒì„±ëœ ì›ê³ ì— ë§ëŠ” ìŠ¤ì¼€ì¤„ ì‹œê°„ ëª©ë¡ ìƒì„±"""
    keyword_to_schedule = {item["keyword"]: item for item in schedule}
    schedule_times = []

    for gen in generated_ids:
        keyword = gen.get("keyword")
        if keyword in keyword_to_schedule:
            schedule_times.append(keyword_to_schedule[keyword]["schedule_time"])
        else:
            schedule_times.append(None)

    return schedule_times


# ========== ë‹¨ì¼ í ì²˜ë¦¬ ==========

async def process_single_queue(
    queue_index: int,
    total_queues: int,
    account: dict,
    keywords: list[str],
    start_date: str,
    start_hour: int,
    posts_per_day: int,
    interval_hours: int,
    service: str,
    ref: str,
    generate_images: bool,
    image_count: int,
    delay_between_posts: int,
) -> dict:
    """ë‹¨ì¼ í ì²˜ë¦¬ (ì›ê³  ìƒì„± â†’ ë¡œê·¸ì¸ â†’ ë°œí–‰)"""
    start_ts = datetime.now()
    account_id = account.get("id")
    password = account.get("password")

    result = {
        "queue_index": queue_index,
        "account": f"{account_id[:3]}***" if account_id else "unknown",
        "status": "pending",
        "schedule": {},
        "summary": {
            "keywords": len(keywords),
            "published": 0,
            "failed": 0,
            "elapsed": 0,
        },
        "daily_summary": {},
        "results": [],
        "error": None,
    }

    if not account_id or not password:
        result["status"] = "failed"
        result["error"] = "ê³„ì • ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        return result

    log.header(f"í {queue_index}/{total_queues}: {account_id[:3]}***", "ğŸ“¦")
    log.kv("í‚¤ì›Œë“œ", f"{len(keywords)}ê°œ")

    try:
        # 1ë‹¨ê³„: ìŠ¤ì¼€ì¤„ ê³„ì‚°
        schedule = calculate_schedule(
            start_date=start_date,
            start_hour=start_hour,
            keywords=keywords,
            posts_per_day=posts_per_day,
            interval_hours=interval_hours,
        )

        total_days = (len(keywords) + posts_per_day - 1) // posts_per_day
        result["schedule"] = {
            "start_date": start_date,
            "start_hour": start_hour,
            "days": total_days,
            "posts_per_day": posts_per_day,
            "interval_hours": interval_hours,
        }

        log.kv("ìŠ¤ì¼€ì¤„", f"{total_days}ì¼, {len(schedule)}ê°œ")

        # 2ë‹¨ê³„: ì›ê³  ìƒì„±
        log.step(1, 4, "ì›ê³  ìƒì„±")
        batch_id, generated_ids = await generate_manuscripts_batch(
            keywords=keywords,
            ref=ref,
            generate_images=generate_images,
            image_count=image_count,
        )

        if not generated_ids:
            result["status"] = "failed"
            result["error"] = "ì›ê³  ìƒì„±ì— ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            return result

        log.success("ì›ê³  ìƒì„± ì™„ë£Œ", count=len(generated_ids))

        # 3ë‹¨ê³„: í ìƒì„±
        log.step(2, 4, "í ìƒì„±")
        queue_id, queue_dir = create_queue(
            manuscript_ids=[item["id"] for item in generated_ids],
            account_id=account_id,
            schedule_date=start_date,
        )

        manuscripts = get_queue_manuscripts(queue_id)
        result["queue_id"] = queue_id
        log.kv("í ID", queue_id)

        # 4ë‹¨ê³„: ë¡œê·¸ì¸
        log.step(3, 4, "ë„¤ì´ë²„ ë¡œê·¸ì¸")
        update_queue_status(queue_id, "processing")

        login_result = await naver_login_with_playwright(
            account_id=account_id,
            password=password,
            debug=True,
        )

        if not login_result["success"]:
            update_queue_status(queue_id, "failed")
            result["status"] = "failed"
            result["error"] = f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_result.get('message')}"
            return result

        cookies = login_result["cookies"]
        log.success("ë¡œê·¸ì¸ ì„±ê³µ", cookies=len(cookies))

        # 5ë‹¨ê³„: ì˜ˆì•½ë°œí–‰
        log.step(4, 4, "ì˜ˆì•½ë°œí–‰")
        schedule_times = build_schedule_times(generated_ids, schedule)

        publish_results = await publish_manuscripts_batch(
            cookies=cookies,
            queue_dir=queue_dir,
            manuscripts=manuscripts,
            schedule_times=schedule_times,
            account_id=account_id,
            delay=delay_between_posts,
        )

        # ê²°ê³¼ì— day/slot ì •ë³´ ì¶”ê°€
        keyword_to_schedule = {item["keyword"]: item for item in schedule}
        for idx, pub_result in enumerate(publish_results):
            gen = generated_ids[idx] if idx < len(generated_ids) else None
            if gen and gen["keyword"] in keyword_to_schedule:
                sched = keyword_to_schedule[gen["keyword"]]
                pub_result["day"] = sched["day"]
                pub_result["slot"] = sched["slot"]
                pub_result["scheduled_at"] = sched["schedule_time"].isoformat()

        # ê²°ê³¼ ì§‘ê³„
        success_count = sum(1 for r in publish_results if r["success"])
        failed_count = len(manuscripts) - success_count
        cleanup_empty_queue(queue_id)

        elapsed = (datetime.now() - start_ts).total_seconds()

        # ì¼ë³„ ìš”ì•½
        daily_summary = {}
        for r in publish_results:
            day = r.get("day", 0)
            if day not in daily_summary:
                daily_summary[day] = {"success": 0, "failed": 0}
            if r["success"]:
                daily_summary[day]["success"] += 1
            else:
                daily_summary[day]["failed"] += 1

        result["status"] = "completed" if failed_count == 0 else "partial"
        result["summary"] = {
            "keywords": len(keywords),
            "published": success_count,
            "failed": failed_count,
            "elapsed": round(elapsed, 1),
        }
        result["daily_summary"] = daily_summary
        result["results"] = publish_results

        log.success(
            f"í {queue_index} ì™„ë£Œ",
            ì„±ê³µ=f"{success_count}/{len(manuscripts)}",
            ì‹œê°„=f"{elapsed:.0f}s"
        )

    except Exception as e:
        result["status"] = "failed"
        result["error"] = str(e)
        log.error(f"í {queue_index} ì‹¤íŒ¨", error=str(e))

    return result


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@router.post("/auto-schedule")
async def auto_schedule_bot(request: AutoScheduleRequest):
    """ìë™ ìŠ¤ì¼€ì¤„ ë°œí–‰: ì›ê³  ìë™ìƒì„± + ì˜ˆì•½ë°œí–‰ (ë°°ì¹˜ í ì§€ì›)

    - queues ë°°ì—´ë¡œ ì—¬ëŸ¬ ê³„ì •/í‚¤ì›Œë“œ ì„¸íŠ¸ ìˆ˜ì‹ 
    - ìˆœì°¨ ì‹¤í–‰: í1 ì™„ë£Œ â†’ í2 â†’ í3 ...
    - ê°œë³„ í ì‹¤íŒ¨ ì‹œ ë‹¤ìŒ íë¡œ ê³„ì† ì§„í–‰
    """
    total_start = datetime.now()
    total_queues = len(request.queues)

    log.header(f"ë°°ì¹˜ ìŠ¤ì¼€ì¤„ ë°œí–‰ ì‹œì‘ ({total_queues}ê°œ í)", "ğŸš€")
    log.kv("ì‹œì‘ì¼", request.start_date)
    log.kv("ì‹œì‘ì‹œê°„", f"{request.start_hour}:00")
    log.kv("ì„¤ì •", f"í•˜ë£¨ {request.posts_per_day}ê°œ / {request.interval_hours}ì‹œê°„ ê°„ê²©")
    log.divider()

    queue_results = []

    for idx, queue_item in enumerate(request.queues):
        queue_index = idx + 1

        # ê°œë³„ ì˜¤ë²„ë¼ì´ë“œ ì ìš©
        posts_per_day = queue_item.posts_per_day or request.posts_per_day
        interval_hours = queue_item.interval_hours or request.interval_hours
        service = queue_item.service or request.service
        ref = queue_item.ref if queue_item.ref is not None else request.ref

        result = await process_single_queue(
            queue_index=queue_index,
            total_queues=total_queues,
            account=queue_item.account,
            keywords=queue_item.keywords,
            start_date=request.start_date,
            start_hour=request.start_hour,
            posts_per_day=posts_per_day,
            interval_hours=interval_hours,
            service=service,
            ref=ref,
            generate_images=request.generate_images,
            image_count=request.image_count,
            delay_between_posts=request.delay_between_posts,
        )

        queue_results.append(result)

        # ë‹¤ìŒ í ì „ ëŒ€ê¸° (ë§ˆì§€ë§‰ í ì œì™¸)
        if idx < total_queues - 1:
            log.debug(f"{request.delay_between_queues}ì´ˆ ëŒ€ê¸° í›„ ë‹¤ìŒ í ì‹œì‘...")
            await asyncio.sleep(request.delay_between_queues)

    # ì „ì²´ ê²°ê³¼ ì§‘ê³„
    total_keywords = sum(r["summary"]["keywords"] for r in queue_results)
    total_published = sum(r["summary"]["published"] for r in queue_results)
    total_failed = sum(r["summary"]["failed"] for r in queue_results)
    total_elapsed = (datetime.now() - total_start).total_seconds()

    log.divider()
    log.header("ë°°ì¹˜ ìŠ¤ì¼€ì¤„ ë°œí–‰ ì™„ë£Œ", "âœ…")
    log.kv("ì´ í", f"{total_queues}ê°œ")
    log.kv("ì´ í‚¤ì›Œë“œ", f"{total_keywords}ê°œ")
    log.kv("ì„±ê³µ", f"{total_published}ê°œ")
    log.kv("ì‹¤íŒ¨", f"{total_failed}ê°œ")
    log.kv("ì†Œìš”ì‹œê°„", f"{total_elapsed:.0f}s")

    return JSONResponse(content={
        "success": True,
        "total_queues": total_queues,
        "summary": {
            "total_keywords": total_keywords,
            "total_published": total_published,
            "total_failed": total_failed,
            "elapsed": round(total_elapsed, 1),
        },
        "queue_results": queue_results,
    })
