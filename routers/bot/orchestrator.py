"""ë¸”ë¡œê·¸ ë´‡ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ API"""

from __future__ import annotations

import json
import shutil
import asyncio
from pathlib import Path
from datetime import datetime, timedelta
from typing import Optional

from fastapi import APIRouter, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

from routers.auth.naver import naver_login_with_playwright
from routers.auth.blog_write import write_blog_post
from utils.logger import log

router = APIRouter(prefix="/bot", tags=["bot-orchestrator"])

# ì›ê³  ì €ì¥ ê²½ë¡œ
MANUSCRIPTS_DIR = Path("manuscripts")
PENDING_DIR = MANUSCRIPTS_DIR / "pending"
COMPLETED_DIR = MANUSCRIPTS_DIR / "completed"
FAILED_DIR = MANUSCRIPTS_DIR / "failed"

for dir_path in [PENDING_DIR, COMPLETED_DIR, FAILED_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

IMAGE_EXTENSIONS = {".jpg", ".jpeg", ".png", ".gif", ".webp", ".bmp"}


# ========== ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ==========

def parse_manuscript_txt(folder: Path) -> dict | None:
    """í´ë” ë‚´ .txt íŒŒì¼ íŒŒì‹± (ì²« ì¤„=ì œëª©, ë‚˜ë¨¸ì§€=ë³¸ë¬¸)"""
    txt_files = [f for f in folder.iterdir() if f.is_file() and f.suffix.lower() == ".txt"]
    if not txt_files:
        return None

    txt_path = txt_files[0]
    with open(txt_path, "r", encoding="utf-8") as f:
        lines = f.read().strip().split("\n")

    if not lines:
        return None

    title = lines[0].strip()
    content = "\n".join(lines[1:]).strip() if len(lines) > 1 else ""

    image_files = [f for f in folder.iterdir() if f.is_file() and f.suffix.lower() in IMAGE_EXTENSIONS]
    images = [str(f) for f in sorted(image_files)]

    return {
        "title": title,
        "content": content,
        "images": images,
        "created_at": datetime.fromtimestamp(txt_path.stat().st_mtime).isoformat(),
    }


def get_manuscript_data(manuscript_dir: Path) -> dict | None:
    """ì›ê³  ë°ì´í„° ë¡œë“œ (txt ë˜ëŠ” json)"""
    data = parse_manuscript_txt(manuscript_dir)
    if data:
        return data

    manifest_path = manuscript_dir / "manuscript.json"
    if manifest_path.exists():
        with open(manifest_path, "r", encoding="utf-8") as f:
            return json.load(f)

    return None


def get_base_time(schedule_date: Optional[str], schedule_start_hour: int) -> datetime:
    """ì˜ˆì•½ ì‹œì‘ ì‹œê°„ ê³„ì‚°"""
    if schedule_date:
        return datetime.strptime(schedule_date, "%Y-%m-%d").replace(
            hour=schedule_start_hour, minute=0, second=0
        )
    return datetime.now()


def calculate_schedule_time(
    base_time: datetime,
    idx: int,
    interval_hours: int,
    interval_minutes: int
) -> datetime:
    """ì˜ˆì•½ ì‹œê°„ ê³„ì‚°"""
    if interval_minutes > 0:
        return base_time + timedelta(minutes=(idx + 1) * interval_minutes)
    return base_time + timedelta(hours=(idx + 1) * interval_hours)


def move_to_completed(manuscript_id: str, manuscript_dir: Path, result: dict, schedule_time: Optional[datetime] = None, account_id: Optional[str] = None):
    """ì™„ë£Œ í´ë”ë¡œ ì´ë™"""
    completed_dir = COMPLETED_DIR / manuscript_id
    if completed_dir.exists():
        shutil.rmtree(completed_dir)
    shutil.move(str(manuscript_dir), str(completed_dir))

    result_data = {
        "post_url": result.get("post_url"),
        "published_at": datetime.now().isoformat(),
    }
    if schedule_time:
        result_data["scheduled_at"] = schedule_time.isoformat()
    if account_id:
        result_data["account"] = account_id[:3] + "***"

    with open(completed_dir / "result.json", "w", encoding="utf-8") as f:
        json.dump(result_data, f, ensure_ascii=False, indent=2)


def move_to_failed(manuscript_id: str, manuscript_dir: Path, result: dict, account_id: Optional[str] = None):
    """ì‹¤íŒ¨ í´ë”ë¡œ ì´ë™"""
    failed_dir = FAILED_DIR / manuscript_id
    if failed_dir.exists():
        shutil.rmtree(failed_dir)
    shutil.move(str(manuscript_dir), str(failed_dir))

    error_data = {
        "error": result.get("message"),
        "failed_at": datetime.now().isoformat(),
    }
    if account_id:
        error_data["account"] = account_id[:3] + "***"

    with open(failed_dir / "error.json", "w", encoding="utf-8") as f:
        json.dump(error_data, f, ensure_ascii=False, indent=2)


async def publish_single_manuscript(
    cookies: list,
    manuscript_id: str,
    schedule_time: Optional[datetime] = None,
    account_id: Optional[str] = None
) -> dict:
    """ë‹¨ì¼ ì›ê³  ë°œí–‰ (ê³µí†µ ë¡œì§)"""
    manuscript_dir = PENDING_DIR / manuscript_id
    data = get_manuscript_data(manuscript_dir)

    if not data:
        return {
            "manuscript_id": manuscript_id,
            "success": False,
            "message": "ì›ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        }

    # ë¡œê·¸ ì¶œë ¥
    if schedule_time:
        log.info(f"ë°œí–‰: {data['title'][:30]}", id=manuscript_id, schedule=schedule_time.strftime('%m/%d %H:%M'))
    else:
        log.info(f"ë°œí–‰: {data['title'][:30]}", id=manuscript_id)

    # ë¸”ë¡œê·¸ ê¸€ì“°ê¸° ì‹¤í–‰
    result = await write_blog_post(
        cookies=cookies,
        title=data["title"],
        content=data["content"],
        tags=data.get("tags"),
        images=data.get("images"),
        is_public=True,
        schedule_time=schedule_time.isoformat() if schedule_time else None,
        debug=True,
    )

    if result["success"]:
        move_to_completed(manuscript_id, manuscript_dir, result, schedule_time, account_id)
        log.success("ë°œí–‰ ì„±ê³µ", id=manuscript_id)
    else:
        move_to_failed(manuscript_id, manuscript_dir, result, account_id)
        log.error("ë°œí–‰ ì‹¤íŒ¨", id=manuscript_id, message=result.get("message"))

    return {
        "manuscript_id": manuscript_id,
        "title": data["title"][:50],
        "success": result["success"],
        "post_url": result.get("post_url"),
        "message": result.get("message"),
    }


# ========== Pydantic ëª¨ë¸ ==========

class ManuscriptData(BaseModel):
    title: str
    content: str
    tags: Optional[list[str]] = None
    category: Optional[str] = None
    images: Optional[list[str]] = None


class PrepareRequest(BaseModel):
    manuscript: ManuscriptData


class PublishRequest(BaseModel):
    cookies: list
    manuscript_id: Optional[str] = None
    count: int = 1
    use_schedule: bool = False
    schedule_date: Optional[str] = None
    schedule_start_hour: int = 10
    schedule_interval_hours: int = 1
    schedule_interval_minutes: int = 0


class StartBotRequest(BaseModel):
    accounts: list[dict]
    posts_per_account: int = 10
    delay_between_posts: int = 60
    use_schedule: bool = True
    schedule_date: Optional[str] = None
    schedule_start_hour: int = 10
    schedule_interval_hours: int = 1
    schedule_interval_minutes: int = 0


class AutoBotRequest(BaseModel):
    """ì „ì²´ ìë™í™” ìš”ì²­ (ìƒì„± â†’ ë°œí–‰)"""
    account: dict  # {"id": "xxx", "password": "xxx"}
    keywords: list[str]  # í‚¤ì›Œë“œ ëª©ë¡
    service: str = "default"  # ì„œë¹„ìŠ¤/ì¹´í…Œê³ ë¦¬
    ref: str = ""  # ì°¸ì¡° ì›ê³ 
    generate_images: bool = True  # ì´ë¯¸ì§€ ìƒì„± ì—¬ë¶€
    image_count: int = 5  # í‚¤ì›Œë“œë‹¹ ì´ë¯¸ì§€ ê°œìˆ˜
    use_schedule: bool = True  # ì˜ˆì•½ë°œí–‰ ì‚¬ìš©
    schedule_date: Optional[str] = None  # ì˜ˆì•½ ë‚ ì§œ (YYYY-MM-DD)
    schedule_start_hour: int = 10  # ì‹œì‘ ì‹œê°„
    schedule_interval_hours: int = 1  # ê°„ê²© (ì‹œê°„)
    delay_between_posts: int = 60  # ê¸€ ì‚¬ì´ ëŒ€ê¸° (ì´ˆ)


class ManuscriptInfo(BaseModel):
    id: str
    title: str
    category: Optional[str]
    images_count: int
    created_at: str


def get_manuscript_list(status: str = "pending") -> list[ManuscriptInfo]:
    """ì›ê³  ëª©ë¡ ì¡°íšŒ"""
    dir_map = {"pending": PENDING_DIR, "completed": COMPLETED_DIR, "failed": FAILED_DIR}
    target_dir = dir_map.get(status, PENDING_DIR)

    manuscripts = []
    if not target_dir.exists():
        return manuscripts

    for folder in sorted(target_dir.iterdir()):
        if not folder.is_dir():
            continue

        data = parse_manuscript_txt(folder)
        if data:
            manuscripts.append(ManuscriptInfo(
                id=folder.name,
                title=data.get("title", "ì œëª© ì—†ìŒ"),
                category=None,
                images_count=len(data.get("images", [])),
                created_at=data.get("created_at", ""),
            ))
        elif (folder / "manuscript.json").exists():
            with open(folder / "manuscript.json", "r", encoding="utf-8") as f:
                json_data = json.load(f)
                images_dir = folder / "images"
                images_count = len(list(images_dir.glob("*"))) if images_dir.exists() else 0
                manuscripts.append(ManuscriptInfo(
                    id=folder.name,
                    title=json_data.get("title", "ì œëª© ì—†ìŒ"),
                    category=json_data.get("category"),
                    images_count=images_count,
                    created_at=json_data.get("created_at", ""),
                ))
    return manuscripts


def get_next_manuscript_id() -> str:
    """ë‹¤ìŒ ì›ê³  ID ìƒì„±"""
    existing = list(PENDING_DIR.iterdir()) + list(COMPLETED_DIR.iterdir()) + list(FAILED_DIR.iterdir())
    max_id = 0
    for folder in existing:
        if folder.is_dir() and folder.name.isdigit():
            max_id = max(max_id, int(folder.name))
    return str(max_id + 1).zfill(4)


# ========== API ì—”ë“œí¬ì¸íŠ¸ ==========

@router.post("/prepare")
async def prepare_manuscript(request: PrepareRequest):
    """ì›ê³  ì €ì¥ (ìˆ˜ë™)"""
    manuscript_id = get_next_manuscript_id()
    manuscript_dir = PENDING_DIR / manuscript_id
    manuscript_dir.mkdir(parents=True, exist_ok=True)

    images_dir = manuscript_dir / "images"
    images_dir.mkdir(exist_ok=True)

    data = {
        "title": request.manuscript.title,
        "content": request.manuscript.content,
        "tags": request.manuscript.tags or [],
        "category": request.manuscript.category,
        "images": request.manuscript.images or [],
        "created_at": datetime.now().isoformat(),
    }

    with open(manuscript_dir / "manuscript.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    log.success("ì›ê³  ì €ì¥ ì™„ë£Œ", id=manuscript_id, title=request.manuscript.title[:30])

    return JSONResponse(content={
        "success": True,
        "manuscript_id": manuscript_id,
        "message": "ì›ê³ ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "images_dir": str(images_dir),
    })


@router.get("/queue")
async def get_queue(status: str = "pending"):
    """ëŒ€ê¸° ì¤‘ì¸ ì›ê³  ëª©ë¡"""
    manuscripts = get_manuscript_list(status)
    return JSONResponse(content={
        "status": status,
        "count": len(manuscripts),
        "manuscripts": [m.model_dump() for m in manuscripts],
    })


@router.get("/manuscript/{manuscript_id}")
async def get_manuscript(manuscript_id: str):
    """íŠ¹ì • ì›ê³  ìƒì„¸ ì¡°íšŒ"""
    for dir_path in [PENDING_DIR, COMPLETED_DIR, FAILED_DIR]:
        manuscript_dir = dir_path / manuscript_id
        if manuscript_dir.exists():
            data = get_manuscript_data(manuscript_dir)
            if data:
                return JSONResponse(content={
                    "id": manuscript_id,
                    "status": dir_path.name,
                    "data": data,
                    "images": data.get("images", []),
                })

    raise HTTPException(status_code=404, detail="ì›ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@router.post("/publish")
async def publish_manuscripts(request: PublishRequest):
    """ì›ê³  ë°œí–‰"""
    manuscripts = get_manuscript_list("pending")

    if not manuscripts:
        raise HTTPException(status_code=404, detail="ë°œí–‰í•  ì›ê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ëŒ€ìƒ ì›ê³  ì„ íƒ
    if request.manuscript_id:
        target_ids = [request.manuscript_id]
    else:
        target_ids = [m.id for m in manuscripts[:request.count]]

    # ì˜ˆì•½ ì‹œê°„ ê³„ì‚°
    base_time = get_base_time(request.schedule_date, request.schedule_start_hour)

    results = []
    for idx, manuscript_id in enumerate(target_ids):
        schedule_time = None
        if request.use_schedule:
            schedule_time = calculate_schedule_time(
                base_time, idx,
                request.schedule_interval_hours,
                request.schedule_interval_minutes
            )

        result = await publish_single_manuscript(
            cookies=request.cookies,
            manuscript_id=manuscript_id,
            schedule_time=schedule_time,
        )
        results.append(result)

    success_count = sum(1 for r in results if r["success"])

    return JSONResponse(content={
        "total": len(results),
        "success": success_count,
        "failed": len(results) - success_count,
        "results": results,
    })


@router.post("/start")
async def start_bot(request: StartBotRequest):
    """ì „ì²´ ë´‡ ì‹¤í–‰ (ê³„ì •ë³„ ë°˜ë³µ)"""
    all_results = []

    for account in request.accounts:
        account_id = account.get("id")
        password = account.get("password")

        if not account_id or not password:
            all_results.append({
                "account": account_id or "unknown",
                "success": False,
                "message": "ID ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.",
                "posts": [],
            })
            continue

        log.header(f"ê³„ì • ë¡œê·¸ì¸: {account_id[:3]}***", "ğŸ‘¤")

        # 1. ë¡œê·¸ì¸
        login_result = await naver_login_with_playwright(
            account_id=account_id,
            password=password,
            debug=True,
        )

        if not login_result["success"]:
            all_results.append({
                "account": account_id[:3] + "***",
                "success": False,
                "message": f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_result.get('message')}",
                "posts": [],
            })
            continue

        cookies = login_result["cookies"]
        log.success("ë¡œê·¸ì¸ ì„±ê³µ", cookies=len(cookies))

        # 2. ì›ê³  ë°œí–‰
        manuscripts = get_manuscript_list("pending")
        base_time = get_base_time(request.schedule_date, request.schedule_start_hour)
        posts_results = []

        for i, manuscript in enumerate(manuscripts[:request.posts_per_account]):
            schedule_time = None
            if request.use_schedule:
                schedule_time = calculate_schedule_time(
                    base_time, i,
                    request.schedule_interval_hours,
                    request.schedule_interval_minutes
                )
                log.step(i + 1, request.posts_per_account, f"{manuscript.title[:25]} (ì˜ˆì•½: {schedule_time.strftime('%m/%d %H:%M')})")
            else:
                log.step(i + 1, request.posts_per_account, f"{manuscript.title[:30]} (ì¦‰ì‹œë°œí–‰)")

            result = await publish_single_manuscript(
                cookies=cookies,
                manuscript_id=manuscript.id,
                schedule_time=schedule_time,
                account_id=account_id,
            )
            posts_results.append(result)

            # ê¸€ ì‚¬ì´ ëŒ€ê¸°
            if i < len(manuscripts[:request.posts_per_account]) - 1:
                log.debug(f"{request.delay_between_posts}ì´ˆ ëŒ€ê¸°...")
                await asyncio.sleep(request.delay_between_posts)

        success_count = sum(1 for p in posts_results if p["success"])

        all_results.append({
            "account": account_id[:3] + "***",
            "success": True,
            "message": f"{success_count}/{len(posts_results)} ë°œí–‰ ì™„ë£Œ",
            "posts": posts_results,
        })

        log.success(f"ê³„ì • ì™„ë£Œ: {account_id[:3]}***", success=f"{success_count}/{len(posts_results)}")

    total_success = sum(
        sum(1 for p in r.get("posts", []) if p.get("success"))
        for r in all_results
    )
    total_posts = sum(len(r.get("posts", [])) for r in all_results)

    return JSONResponse(content={
        "total_accounts": len(request.accounts),
        "total_posts": total_posts,
        "total_success": total_success,
        "results": all_results,
    })


@router.delete("/manuscript/{manuscript_id}")
async def delete_manuscript(manuscript_id: str):
    """ì›ê³  ì‚­ì œ"""
    for dir_path in [PENDING_DIR, COMPLETED_DIR, FAILED_DIR]:
        manuscript_dir = dir_path / manuscript_id
        if manuscript_dir.exists():
            shutil.rmtree(manuscript_dir)
            return JSONResponse(content={
                "success": True,
                "message": f"ì›ê³  {manuscript_id} ì‚­ì œ ì™„ë£Œ",
            })

    raise HTTPException(status_code=404, detail="ì›ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


@router.post("/retry/{manuscript_id}")
async def retry_manuscript(manuscript_id: str):
    """ì‹¤íŒ¨í•œ ì›ê³  ì¬ì‹œë„ (pendingìœ¼ë¡œ ì´ë™)"""
    failed_dir = FAILED_DIR / manuscript_id
    if not failed_dir.exists():
        raise HTTPException(status_code=404, detail="ì‹¤íŒ¨í•œ ì›ê³ ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    error_file = failed_dir / "error.json"
    if error_file.exists():
        error_file.unlink()

    pending_dir = PENDING_DIR / manuscript_id
    shutil.move(str(failed_dir), str(pending_dir))

    return JSONResponse(content={
        "success": True,
        "message": f"ì›ê³  {manuscript_id}ë¥¼ ì¬ì‹œë„ ëŒ€ê¸°ì—´ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.",
    })


@router.get("/health")
async def health():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "service": "bot-orchestrator",
        "queue": {
            "pending": len(get_manuscript_list("pending")),
            "completed": len(get_manuscript_list("completed")),
            "failed": len(get_manuscript_list("failed")),
        }
    }


@router.post("/auto")
async def auto_bot(request: AutoBotRequest):
    """
    ì „ì²´ ìë™í™”: ì›ê³ +ì´ë¯¸ì§€ ìƒì„± â†’ ë¡œê·¸ì¸ â†’ ë°œí–‰

    1. í‚¤ì›Œë“œë³„ë¡œ ì›ê³  + ì´ë¯¸ì§€ ìƒì„±
    2. pending í´ë”ì— ì €ì¥
    3. ë„¤ì´ë²„ ë¡œê·¸ì¸
    4. ì˜ˆì•½ë°œí–‰
    """
    from routers.generate.batch import generate_images_parallel, save_to_pending
    from llm.gpt4o_service import gpt4o_gen
    from utils.get_category_db_name import get_category_db_name
    from fastapi.concurrency import run_in_threadpool

    start_ts = datetime.now()
    account_id = request.account.get("id")
    password = request.account.get("password")

    if not account_id or not password:
        raise HTTPException(status_code=400, detail="ê³„ì • ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    log.header("ì „ì²´ ìë™í™” ì‹œì‘", "ğŸ¤–")
    log.kv("ê³„ì •", f"{account_id[:3]}***")
    log.kv("í‚¤ì›Œë“œ", f"{len(request.keywords)}ê°œ")
    log.kv("ì´ë¯¸ì§€", "ON" if request.generate_images else "OFF")

    # ========== 1ë‹¨ê³„: ì›ê³  + ì´ë¯¸ì§€ ìƒì„± ==========
    log.header("1ë‹¨ê³„: ì›ê³  ìƒì„±", "ğŸ“")
    generated_ids = []

    for idx, keyword in enumerate(request.keywords):
        keyword = keyword.strip()
        if not keyword:
            continue

        log.step(idx + 1, len(request.keywords), keyword[:30])

        try:
            # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
            category = await get_category_db_name(keyword=keyword + request.ref)

            # ì›ê³  ìƒì„±
            content = await run_in_threadpool(
                gpt4o_gen,
                user_instructions=keyword,
                ref=request.ref,
                category=category
            )

            if not content:
                log.error(f"ì›ê³  ìƒì„± ì‹¤íŒ¨", keyword=keyword[:20])
                continue

            # ì´ë¯¸ì§€ ìƒì„±
            image_urls = []
            if request.generate_images:
                images = await run_in_threadpool(
                    generate_images_parallel,
                    keyword,
                    request.image_count
                )
                image_urls = [img["url"] for img in images if img.get("url")]

            # pendingì— ì €ì¥
            manuscript_id = await save_to_pending(keyword, content, image_urls)
            generated_ids.append(manuscript_id)
            log.success(f"ìƒì„± ì™„ë£Œ", id=manuscript_id, images=len(image_urls))

        except Exception as e:
            log.error(f"ìƒì„± ì—ëŸ¬", keyword=keyword[:20], error=str(e))

        await asyncio.sleep(1)

    if not generated_ids:
        raise HTTPException(status_code=500, detail="ì›ê³  ìƒì„±ì— ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    log.success(f"ì›ê³  ìƒì„± ì™„ë£Œ", count=len(generated_ids))

    # ========== 2ë‹¨ê³„: ë¡œê·¸ì¸ ==========
    log.header("2ë‹¨ê³„: ë„¤ì´ë²„ ë¡œê·¸ì¸", "ğŸ”")

    login_result = await naver_login_with_playwright(
        account_id=account_id,
        password=password,
        debug=True,
    )

    if not login_result["success"]:
        raise HTTPException(
            status_code=401,
            detail=f"ë¡œê·¸ì¸ ì‹¤íŒ¨: {login_result.get('message')}"
        )

    cookies = login_result["cookies"]
    log.success("ë¡œê·¸ì¸ ì„±ê³µ", cookies=len(cookies))

    # ========== 3ë‹¨ê³„: ë°œí–‰ ==========
    log.header("3ë‹¨ê³„: ë¸”ë¡œê·¸ ë°œí–‰", "ğŸ“¤")

    base_time = get_base_time(request.schedule_date, request.schedule_start_hour)
    publish_results = []

    for idx, manuscript_id in enumerate(generated_ids):
        schedule_time = None
        if request.use_schedule:
            schedule_time = calculate_schedule_time(
                base_time, idx,
                request.schedule_interval_hours, 0
            )
            log.step(idx + 1, len(generated_ids), f"ID:{manuscript_id} (ì˜ˆì•½: {schedule_time.strftime('%m/%d %H:%M')})")
        else:
            log.step(idx + 1, len(generated_ids), f"ID:{manuscript_id} (ì¦‰ì‹œ)")

        result = await publish_single_manuscript(
            cookies=cookies,
            manuscript_id=manuscript_id,
            schedule_time=schedule_time,
            account_id=account_id,
        )
        publish_results.append(result)

        if idx < len(generated_ids) - 1:
            await asyncio.sleep(request.delay_between_posts)

    # ========== ê²°ê³¼ ==========
    elapsed = (datetime.now() - start_ts).total_seconds()
    success_count = sum(1 for r in publish_results if r["success"])

    log.divider()
    log.success(f"ìë™í™” ì™„ë£Œ", ì„±ê³µ=f"{success_count}/{len(generated_ids)}", ì‹œê°„=f"{elapsed:.0f}s")

    return JSONResponse(content={
        "success": True,
        "account": f"{account_id[:3]}***",
        "generated": len(generated_ids),
        "published": success_count,
        "failed": len(generated_ids) - success_count,
        "elapsed": round(elapsed, 1),
        "results": publish_results,
    })
