# ğŸ¤– Blog Analyzer AI Agent

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”
**FastAPI ê¸°ë°˜ ë¸”ë¡œê·¸ ì›ê³  ë¶„ì„ ë° AI ìƒì„± ë„êµ¬**
- **ì–¸ì–´**: Python 3.7+
- **ì£¼ ëª©ì **: ê¸°ì¡´ ì›ê³  ë¶„ì„ â†’ AI ê¸°ë°˜ ì‹ ê·œ ì›ê³  ìë™ ìƒì„±
- **í”„ë ˆì„ì›Œí¬**: FastAPI + Uvicorn
- **ë°ì´í„°ë² ì´ìŠ¤**: MongoDB (pymongo)
- **AI ì„œë¹„ìŠ¤**: GPT-4/5, Claude, Gemini, Solar(Upstage)
- **ìì—°ì–´ì²˜ë¦¬**: KoNLPy, KSS (í•œêµ­ì–´ íŠ¹í™”)
- **CLI ë„êµ¬**: Click

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ğŸ–¥ï¸ CLI ë„êµ¬ (main.py)
```bash
# ë©”ë‰´í˜• ëŒ€í™”ì‹ CLI - ë¶„ì„ë¶€í„° ìƒì„±ê¹Œì§€ ì „ ê³¼ì •
python main.py
```
**ë¶„ì„ íŒŒì´í”„ë¼ì¸**: í˜•íƒœì†Œ ë¶„ì„ â†’ ë¬¸ì¥ ë¶„ë¦¬ â†’ í‘œí˜„ ì¶”ì¶œ â†’ íŒŒë¼ë¯¸í„° ë¶„ì„ â†’ í…œí”Œë¦¿ ìƒì„± â†’ ì›ê³  ìƒì„±

### ğŸŒ API ì„œë²„ (api.py)
```bash
# FastAPI ì„œë²„ - RESTful API ì œê³µ
uvicorn api:app --reload --host 0.0.0.0 --port 8000
```

### ğŸ“¡ ì£¼ìš” API ì—”ë“œí¬ì¸íŠ¸
```
ğŸ¤– AI ì›ê³  ìƒì„±
POST /generate/gpt         # GPT-4 ì›ê³  ìƒì„±
POST /generate/gpt_5       # GPT-5 ì›ê³  ìƒì„±
POST /generate/claude      # Claude ì›ê³  ìƒì„±
POST /generate/gemini      # Gemini ì›ê³  ìƒì„±
POST /generate/solar       # Solar ì›ê³  ìƒì„±
POST /generate/kkk         # KKK í”„ë¡¬í”„íŠ¸ íŠ¹í™” ìƒì„±
POST /generate/chunk       # ì²­í¬ ë‹¨ìœ„ ë¶„í•  ìƒì„±
POST /generate/step_by_step # ë‹¨ê³„ë³„ ìƒì„±

ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„
POST /analysis/upload_text     # í…ìŠ¤íŠ¸ ë¶„ì„ ì—…ë¡œë“œ
POST /analysis/get_sub_title   # ë¶€ì œëª© ì¶”ì¶œ

ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ê´€ë¦¬
POST /category/keyword         # í‚¤ì›Œë“œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
```

---

## ğŸ“ í•µì‹¬ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
blog_analyzer/
â”œâ”€â”€ ğŸš€ main.py                 # CLI ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸ (ë©”ë‰´í˜•)
â”œâ”€â”€ ğŸŒ api.py                  # FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”œâ”€â”€ âš™ï¸ config.py               # í™˜ê²½ë³€ìˆ˜ ë° API í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
â”œâ”€â”€ ğŸ—„ï¸ mongodb_service.py      # MongoDB ì—°ê²° ë° CRUD ì„œë¹„ìŠ¤
â”œâ”€â”€ ğŸ“¡ routers/               # FastAPI ë¼ìš°í„°ë“¤
â”‚   â”œâ”€â”€ generate/             # ğŸ¤– AI ì›ê³  ìƒì„± ë¼ìš°í„°ë“¤
â”‚   â”‚   â”œâ”€â”€ gpt.py           # GPT-4 ìƒì„±
â”‚   â”‚   â”œâ”€â”€ gpt_5.py         # GPT-5 ìƒì„±
â”‚   â”‚   â”œâ”€â”€ claude.py        # Claude ìƒì„±
â”‚   â”‚   â”œâ”€â”€ gemini.py        # Gemini ìƒì„±
â”‚   â”‚   â”œâ”€â”€ solar.py         # Solar ìƒì„±
â”‚   â”‚   â”œâ”€â”€ kkk.py          # KKK í”„ë¡¬í”„íŠ¸ íŠ¹í™”
â”‚   â”‚   â”œâ”€â”€ chunk.py        # ì²­í¬ ë¶„í•  ìƒì„±
â”‚   â”‚   â””â”€â”€ step_by_step.py # ë‹¨ê³„ë³„ ìƒì„±
â”‚   â”œâ”€â”€ analysis/             # ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ë¼ìš°í„°ë“¤
â”‚   â””â”€â”€ category/             # ğŸ—‚ï¸ ì¹´í…Œê³ ë¦¬ ê´€ë ¨ ë¼ìš°í„°ë“¤
â”œâ”€â”€ ğŸ§  llm/                   # LLM ì„œë¹„ìŠ¤ ë¡œì§
â”‚   â”œâ”€â”€ gpt_4_service.py     # GPT-4 êµ¬í˜„ì²´
â”‚   â”œâ”€â”€ claude_service.py    # Claude êµ¬í˜„ì²´
â”‚   â”œâ”€â”€ gemini_service.py    # Gemini êµ¬í˜„ì²´
â”‚   â”œâ”€â”€ chunk_service.py     # ì²­í¬ ì²˜ë¦¬ ë¡œì§
â”‚   â””â”€â”€ kkk_service.py      # KKK í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
â”œâ”€â”€ ğŸ”¬ analyzer/              # ìì—°ì–´ í…ìŠ¤íŠ¸ ë¶„ì„ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ morpheme.py          # í˜•íƒœì†Œ ë¶„ì„ (KoNLPy)
â”‚   â”œâ”€â”€ sentence.py          # ë¬¸ì¥ ë¶„ë¦¬ (KSS)
â”‚   â”œâ”€â”€ expression.py        # í‘œí˜„ ì¶”ì¶œ (AI ê¸°ë°˜)
â”‚   â””â”€â”€ parameter.py         # íŒŒë¼ë¯¸í„° ë¶„ì„ (AI ê¸°ë°˜)
â”œâ”€â”€ ğŸ“„ schema/                # Pydantic ìŠ¤í‚¤ë§ˆ ì •ì˜
â”œâ”€â”€ ğŸ› ï¸ utils/                 # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ ğŸ’¬ _prompts/              # AI í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”œâ”€â”€ ğŸ“Š _constants/            # ìƒìˆ˜ ì •ì˜ (ëª¨ë¸ëª… ë“±)
â””â”€â”€ ğŸ“š _docs/                 # ë¬¸ì„œ ê´€ë ¨ íŒŒì¼ë“¤
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥ íë¦„

### 1ï¸âƒ£ í…ìŠ¤íŠ¸ ë¶„ì„ íŒŒì´í”„ë¼ì¸
```
ğŸ“ ì›ê³  í…ìŠ¤íŠ¸ íŒŒì¼ë“¤
    â†“
ğŸ”¬ 1. í˜•íƒœì†Œ ë¶„ì„ (KoNLPy) â†’ ë‹¨ì–´ ì¶”ì¶œ
    â†“
ğŸ“ 2. ë¬¸ì¥ ë¶„ë¦¬ (KSS) â†’ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬
    â†“
ğŸ¨ 3. í‘œí˜„ ì¶”ì¶œ (AI) â†’ ê¸€ì“°ê¸° í‘œí˜„ íŒ¨í„´ ì¶”ì¶œ
    â†“
ğŸ·ï¸ 4. íŒŒë¼ë¯¸í„° ë¶„ì„ (AI) â†’ ê°œì²´ëª… ì¸ì‹ ë° ê·¸ë£¹í™”
    â†“
ğŸ“‹ 5. í…œí”Œë¦¿ ìƒì„± â†’ íŒŒë¼ë¯¸í„°ë¥¼ ë³€ìˆ˜í™”í•œ í…œí”Œë¦¿
    â†“
ğŸ—„ï¸ MongoDB ì €ì¥ (ë¶„ì„ ê²°ê³¼ ì¶•ì )
```

### 2ï¸âƒ£ AI ì›ê³  ìƒì„± ì›Œí¬í”Œë¡œìš°
```
ğŸ“Š ì‚¬ìš©ì í‚¤ì›Œë“œ + ì°¸ì¡° ì›ê³  (ì„ íƒ)
    â†“
ğŸ—„ï¸ MongoDBì—ì„œ ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ
    â†“
ğŸ’¬ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‹œìŠ¤í…œ + ì‚¬ìš©ì + ë¶„ì„ ê²°ê³¼)
    â†“
ğŸ¤– AI ëª¨ë¸ í˜¸ì¶œ (GPT/Claude/Gemini/Solar)
    â†“
âœ¨ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ë° ì •ì œ
    â†“
ğŸ—„ï¸ ìƒì„± ê²°ê³¼ MongoDB ì €ì¥ + API ì‘ë‹µ
```

---

## ğŸ¯ **Python ë„¤ì´ë° ì»¨ë²¤ì…˜ (í•„ìˆ˜)**

### **1. ë³€ìˆ˜ & í•¨ìˆ˜ - snake_case**
```python
# âœ… ì˜¬ë°”ë¥¸ ë„¤ì´ë°
user_name = "john"
user_list = ["john", "jane"]
is_logged_in = True
has_permission = False

# í•¨ìˆ˜ (ë™ì‚¬ + ëª…ì‚¬)
def get_user_info():
    pass

def create_review():
    pass

def update_content():
    pass

def handle_login_click():
    pass

# âŒ ì˜ëª»ëœ ë„¤ì´ë°
userName = "john"          # camelCase ê¸ˆì§€
userList = ["john"]        # camelCase ê¸ˆì§€
isLoggedIn = True          # camelCase ê¸ˆì§€
hasRef = False             # camelCase ê¸ˆì§€
```

### **2. í´ë˜ìŠ¤ - PascalCase**
```python
# âœ… ì˜¬ë°”ë¥¸ í´ë˜ìŠ¤ëª…
class UserService:
    pass

class MongoDBService:
    pass

class GenerateRequest:
    pass

# âŒ ì˜ëª»ëœ í´ë˜ìŠ¤ëª…
class userService:         # ì†Œë¬¸ì ì‹œì‘ ê¸ˆì§€
class generate_request:    # snake_case ê¸ˆì§€
```

### **3. ìƒìˆ˜ - UPPER_SNAKE_CASE**
```python
# âœ… ì˜¬ë°”ë¥¸ ìƒìˆ˜ëª…
OPENAI_API_KEY = "sk-..."
MONGO_URI = "mongodb://..."
MAX_TEXT_LENGTH = 3200
MIN_TEXT_LENGTH = 3000
DEFAULT_MODEL_NAME = "gpt-4"

# âŒ ì˜ëª»ëœ ìƒìˆ˜ëª…
openai_api_key = "sk-..."  # ì†Œë¬¸ì ê¸ˆì§€
maxTextLength = 3200       # camelCase ê¸ˆì§€
```

### **4. íŒŒì¼ & ëª¨ë“ˆ - snake_case**
```python
# âœ… ì˜¬ë°”ë¥¸ íŒŒì¼ëª…
gpt_service.py
claude_service.py
mongodb_service.py
text_cleaner.py
query_parser.py

# âŒ ì˜ëª»ëœ íŒŒì¼ëª…
gptService.py              # camelCase ê¸ˆì§€
ClaudeService.py           # PascalCase ê¸ˆì§€
```

### **5. ë¹„ê³µê°œ ë³€ìˆ˜/í•¨ìˆ˜ - _leading_underscore**
```python
# âœ… ë¹„ê³µê°œ ë³€ìˆ˜/í•¨ìˆ˜
class AIService:
    def __init__(self):
        self._api_key = "secret"      # ë¹„ê³µê°œ ë³€ìˆ˜
        self.__client = None          # ê°•í•œ ë¹„ê³µê°œ
    
    def _parse_response(self):        # ë¹„ê³µê°œ ë©”ì„œë“œ
        pass
    
    def generate_text(self):          # ê³µê°œ ë©”ì„œë“œ
        return self._parse_response()
```

---

## ğŸ”§ **FastAPI íŒ¨í„´ (í‘œì¤€í™”)**

### **1. ë¼ìš°í„° ê¸°ë³¸ í…œí”Œë¦¿**
```python
from fastapi import APIRouter, HTTPException
from fastapi.concurrency import run_in_threadpool

from mongodb_service import MongoDBService
from schema.generate import GenerateRequest
from utils.get_category_db_name import get_category_db_name
from llm.gpt_service import gpt_generate, MODEL_NAME

router = APIRouter()

@router.post("/generate/service")
async def generate_endpoint(request: GenerateRequest):
    """
    AI ì›ê³  ìƒì„± ì—”ë“œí¬ì¸íŠ¸
    """
    service = request.service.lower()
    keyword = request.keyword.strip()
    ref_content = request.ref
    
    category = get_category_db_name(keyword=keyword)
    
    # MongoDB ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    db_service = MongoDBService()
    db_service.set_db_name(db_name=category)
    
    # ë””ë²„ê·¸ ë¡œê¹…
    is_ref = bool(ref_content and ref_content.strip())
    print(f"[GEN] service={service} | model={MODEL_NAME} | category={category} | keyword={keyword} | has_ref={is_ref}")
    
    try:
        # ë¹„ë™ê¸° AI í˜¸ì¶œ
        generated_text = await run_in_threadpool(
            gpt_generate, 
            user_instructions=keyword, 
            ref=ref_content
        )
        
        if generated_text:
            # MongoDB ì €ì¥
            document = {
                "content": generated_text,
                "timestamp": time.time(),
                "engine": MODEL_NAME,
                "keyword": keyword,
                "category": category,
            }
            
            db_service.insert_document("manuscripts", document)
            document["_id"] = str(document["_id"])
            
            return document
        else:
            raise HTTPException(
                status_code=500,
                detail="ì›ê³  ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            )
            
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ë‚´ë¶€ ì˜¤ë¥˜: {e}")
    finally:
        db_service.close_connection()
```

### **2. ì—ëŸ¬ ì²˜ë¦¬ í‘œì¤€ íŒ¨í„´**
```python
try:
    # ë©”ì¸ ë¡œì§
    result = ai_service.generate(prompt)
    return result
    
except ValueError as e:
    # ì‚¬ìš©ì ì…ë ¥ ì˜¤ë¥˜
    raise HTTPException(status_code=400, detail=str(e))
    
except ConnectionError as e:
    # ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ê²° ì˜¤ë¥˜
    raise HTTPException(status_code=503, detail=f"ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
    
except Exception as e:
    # ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜
    raise HTTPException(status_code=500, detail=f"ë‚´ë¶€ ì˜¤ë¥˜: {e}")
    
finally:
    # ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (í•„ìˆ˜)
    if db_service:
        db_service.close_connection()
```

---

## ğŸ¤– **AI ì„œë¹„ìŠ¤ íŒ¨í„´ (í‘œì¤€í™”)**

### **1. AI ì„œë¹„ìŠ¤ í•¨ìˆ˜ í…œí”Œë¦¿**
```python
import time
from typing import Optional

from config import OPENAI_API_KEY, openai_client
from _constants.models import GPT_MODEL
from _prompts.get_system_prompt import get_system_prompt
from utils.query_parser import parse_query
from utils.text_cleaner import comprehensive_text_clean
from utils.format_paragraphs import format_paragraphs

def ai_generate_text(user_instructions: str, ref_content: str = "", category: str = "") -> str:
    """
    AI í…ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜
    
    Args:
        user_instructions: ì‚¬ìš©ì ì§€ì‹œì‚¬í•­
        ref_content: ì°¸ì¡° ì›ê³  (ì„ íƒì )
        category: ì¹´í…Œê³ ë¦¬ (ì„ íƒì )
    
    Returns:
        ìƒì„±ëœ í…ìŠ¤íŠ¸ (ì •ì œë¨)
    
    Raises:
        ValueError: API í‚¤ ë¯¸ì„¤ì •, í‚¤ì›Œë“œ ì—†ìŒ ë“±
        RuntimeError: AI ì‘ë‹µ ì˜¤ë¥˜
        Exception: ê¸°íƒ€ ì˜ˆì™¸
    """
    
    # 1. API í‚¤ ê²€ì¦
    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    # 2. ì¿¼ë¦¬ íŒŒì‹±
    parsed_query = parse_query(user_instructions)
    
    if not parsed_query["keyword"]:
        raise ValueError("í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    keyword = parsed_query["keyword"]
    
    # 3. í”„ë¡¬í”„íŠ¸ ìƒì„±
    system_prompt = get_system_prompt(category=category)
    user_prompt = build_user_prompt(parsed_query, ref_content)
    
    # 4. AI í˜¸ì¶œ
    try:
        start_time = time.time()
        print(f"AI ìƒì„± ì‹œì‘: {keyword}")
        
        response = openai_client.chat.completions.create(
            model=GPT_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        
        # 5. í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹…
        if hasattr(response, 'usage') and response.usage:
            prompt_tokens = response.usage.prompt_tokens
            completion_tokens = response.usage.completion_tokens
            total_tokens = response.usage.total_tokens
            print(f"í† í° ì‚¬ìš©ëŸ‰: in={prompt_tokens}, out={completion_tokens}, total={total_tokens}")
        
        # 6. ì‘ë‹µ ê²€ì¦
        if not response.choices or not response.choices[0].message:
            raise RuntimeError("AIê°€ ìœ íš¨í•œ ì‘ë‹µì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        generated_text = response.choices[0].message.content.strip()
        
        if not generated_text:
            raise RuntimeError("AIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")
        
        # 7. í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
        formatted_text = format_paragraphs(generated_text)
        cleaned_text = comprehensive_text_clean(formatted_text)
        
        # 8. ì„±ëŠ¥ ë¡œê¹…
        elapsed_time = time.time() - start_time
        text_length = len(cleaned_text.replace(" ", ""))
        print(f"AI ìƒì„± ì™„ë£Œ: {elapsed_time:.2f}s, ê¸¸ì´: {text_length}ì")
        
        return cleaned_text
        
    except Exception as e:
        print(f"AI ìƒì„± ì˜¤ë¥˜: {e}")
        raise

def build_user_prompt(parsed_query: dict, ref_content: str) -> str:
    """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
    keyword = parsed_query["keyword"]
    note = parsed_query.get("note", "")
    
    prompt = f"""
[ê°œìš”]
{keyword}

ìœ„ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›ê³ ë¥¼ ì‘ì„±í•´ì¤˜

{'[ì°¸ì¡° ì›ê³ ]' if ref_content else ''}
{ref_content}

{'[ì¶”ê°€ ìš”êµ¬ì‚¬í•­]' if note else ''}
{note}
""".strip()
    
    return prompt
```

---

## ğŸ“¦ **Pydantic ìŠ¤í‚¤ë§ˆ íŒ¨í„´**

### **1. ìš”ì²­/ì‘ë‹µ ìŠ¤í‚¤ë§ˆ**
```python
from typing import Optional
from pydantic import BaseModel, Field

class GenerateRequest(BaseModel):
    """AI ì›ê³  ìƒì„± ìš”ì²­ ìŠ¤í‚¤ë§ˆ"""
    service: str = Field(..., description="AI ì„œë¹„ìŠ¤ëª…")
    keyword: str = Field(..., min_length=1, description="ìƒì„± í‚¤ì›Œë“œ")
    ref: str = Field("", description="ì°¸ì¡° ì›ê³ ")

class GenerateResponse(BaseModel):
    """AI ì›ê³  ìƒì„± ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    content: str = Field(..., description="ìƒì„±ëœ ì›ê³ ")
    timestamp: float = Field(..., description="ìƒì„± ì‹œê°„")
    engine: str = Field(..., description="ì‚¬ìš©ëœ AI ëª¨ë¸")
    keyword: str = Field(..., description="í‚¤ì›Œë“œ")
    category: str = Field(..., description="ì¹´í…Œê³ ë¦¬")

class APIResponse(BaseModel):
    """ê³µí†µ API ì‘ë‹µ ìŠ¤í‚¤ë§ˆ"""
    success: bool = Field(..., description="ì„±ê³µ ì—¬ë¶€")
    data: Optional[dict] = Field(None, description="ì‘ë‹µ ë°ì´í„°")
    message: str = Field("", description="ì‘ë‹µ ë©”ì‹œì§€")
    timestamp: float = Field(..., description="ì‘ë‹µ ì‹œê°„")
```

---

## ğŸ—‚ï¸ **MongoDB ì„œë¹„ìŠ¤ íŒ¨í„´**

### **1. í‘œì¤€ MongoDB ì‚¬ìš© íŒ¨í„´**
```python
def save_generated_content(keyword: str, content: str, category: str):
    """ìƒì„±ëœ ì»¨í…ì¸  ì €ì¥"""
    db_service = MongoDBService()
    db_service.set_db_name(db_name=category)
    
    try:
        document = {
            "content": content,
            "timestamp": time.time(),
            "keyword": keyword,
            "category": category,
        }
        
        result_id = db_service.insert_document("manuscripts", document)
        print(f"ë¬¸ì„œ ì €ì¥ ì™„ë£Œ: {result_id}")
        
        return result_id
        
    except Exception as e:
        print(f"ë¬¸ì„œ ì €ì¥ ì‹¤íŒ¨: {e}")
        raise
    finally:
        db_service.close_connection()
```

---

## ğŸ“‹ **Import ìˆœì„œ í‘œì¤€**

```python
# 1. Python í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os
import time
import re
from typing import Optional, List, Dict, Any

# 2. ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬
from fastapi import APIRouter, HTTPException
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel, Field
from openai import OpenAI

# 3. í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ (ì•ŒíŒŒë²³ ìˆœ)
from config import OPENAI_API_KEY, openai_client
from mongodb_service import MongoDBService
from schema.generate import GenerateRequest
from utils.get_category_db_name import get_category_db_name
from utils.query_parser import parse_query
from utils.text_cleaner import comprehensive_text_clean
```

---

## ğŸš¨ **ìƒìˆ˜ ê´€ë¦¬ ê°œì„ **

### **1. _constants/ í´ë” êµ¬ì¡°**
```python
# _constants/config.py
class TextConfig:
    MIN_LENGTH: int = 3000
    MAX_LENGTH: int = 3200
    MAX_LINE_LENGTH: int = 50
    PARAGRAPH_BREAK_COUNT: int = 2

# _constants/models.py  
class AIModels:
    GPT_4 = "gpt-4"
    GPT_5 = "gpt-5"
    CLAUDE_3 = "claude-3-sonnet"
    GEMINI_PRO = "gemini-pro"

# _constants/messages.py
class ErrorMessages:
    API_KEY_MISSING = "API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    KEYWORD_MISSING = "í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤."
    EMPTY_RESPONSE = "AIê°€ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤."
```

### **2. ìƒìˆ˜ ì‚¬ìš© ì˜ˆì‹œ**
```python
from _constants.config import TextConfig
from _constants.models import AIModels
from _constants.messages import ErrorMessages

# ì‚¬ìš©
if len(text) < TextConfig.MIN_LENGTH:
    raise ValueError(f"í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ {TextConfig.MIN_LENGTH}ì ë¯¸ë§Œì…ë‹ˆë‹¤.")

model = AIModels.GPT_4

if not api_key:
    raise ValueError(ErrorMessages.API_KEY_MISSING)
```

---

## ğŸ” **ë¡œê¹… ì‹œìŠ¤í…œ ê°œì„ **

### **1. ë¡œê¹… ì„¤ì •**
```python
import logging
from typing import Optional

# utils/logger.py
def setup_logger(name: str, level: int = logging.INFO) -> logging.Logger:
    """ë¡œê±° ì„¤ì •"""
    logger = logging.getLogger(name)
    logger.setLevel(level)
    
    if not logger.handlers:
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
    
    return logger

# ê° ëª¨ë“ˆì—ì„œ ì‚¬ìš©
logger = setup_logger(__name__)
```

### **2. ë¡œê¹… ì‚¬ìš© íŒ¨í„´**
```python
# print ëŒ€ì‹  logger ì‚¬ìš©
logger.info(f"AI ìƒì„± ì‹œì‘: {keyword}")
logger.warning(f"ì°¸ì¡° ì›ê³ ê°€ ì—†ìŠµë‹ˆë‹¤: {keyword}")
logger.error(f"AI ìƒì„± ì‹¤íŒ¨: {error}")
logger.debug(f"í† í° ì‚¬ìš©ëŸ‰: {tokens}")
```

---

## ğŸ¯ **ê°œë°œ ì²´í¬ë¦¬ìŠ¤íŠ¸**

### **âœ… ë³€ìˆ˜/í•¨ìˆ˜ ë„¤ì´ë°**
- [ ] ëª¨ë“  ë³€ìˆ˜ëŠ” `snake_case`ì¸ê°€?
- [ ] ëª¨ë“  í´ë˜ìŠ¤ëŠ” `PascalCase`ì¸ê°€?
- [ ] ëª¨ë“  ìƒìˆ˜ëŠ” `UPPER_SNAKE_CASE`ì¸ê°€?
- [ ] camelCase ë³€ìˆ˜ëŠ” ëª¨ë‘ ì œê±°í–ˆëŠ”ê°€?

### **âœ… ì½”ë“œ êµ¬ì¡°**
- [ ] Import ìˆœì„œê°€ í‘œì¤€ì— ë§ëŠ”ê°€?
- [ ] íƒ€ì… íŒíŠ¸ë¥¼ ì‚¬ìš©í–ˆëŠ”ê°€?
- [ ] ì—ëŸ¬ ì²˜ë¦¬ê°€ ì ì ˆí•œê°€?
- [ ] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ë¥¼ finallyì—ì„œ í–ˆëŠ”ê°€?

### **âœ… AI ì„œë¹„ìŠ¤**
- [ ] API í‚¤ ê²€ì¦ì„ í–ˆëŠ”ê°€?
- [ ] ì‘ë‹µ ê²€ì¦ì„ í–ˆëŠ”ê°€?
- [ ] í† í° ì‚¬ìš©ëŸ‰ì„ ë¡œê¹…í–ˆëŠ”ê°€?
- [ ] í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ë¥¼ í–ˆëŠ”ê°€?

---

## ğŸš€ **ë³€ìˆ˜ëª… ì¼ê´„ ìˆ˜ì • ê°€ì´ë“œ**

### **ìˆ˜ì •í•´ì•¼ í•  ë³€ìˆ˜ë“¤**
```python
# âŒ í˜„ì¬ â†’ âœ… ìˆ˜ì • í›„
hasRef â†’ has_ref
isRef â†’ is_ref
userId â†’ user_id
userName â†’ user_name
apiKey â†’ api_key
dbName â†’ db_name
modelName â†’ model_name
generatedText â†’ generated_text
userInstructions â†’ user_instructions
refContent â†’ ref_content
```

ë‚˜ëŠ”! ë‚˜ëŠ”..! íŒŒì´ì¬ ì»¨ë²¤ì…˜ì„ ì™„ë²½í•˜ê²Œ ì •ë¦¬í–ˆë‹¤!! ğŸ¯

ì´ì œ ëª¨ë“  camelCase ë³€ìˆ˜ë“¤ì„ snake_caseë¡œ ë°”ê¾¸ë©´ ì™„ì „íˆ íŒŒì´ì¬ìŠ¤ëŸ¬ìš´ ì½”ë“œê°€ ë  ê±°ì•¼!

ì ì‹œ ì†Œë€ì´ ìˆì—ˆì–´ìš”~ ğŸª