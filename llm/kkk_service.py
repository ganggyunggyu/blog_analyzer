from __future__ import annotations
import re
import time

from openai import OpenAI
from _prompts.constants import alticle_nat_prompt, article_flow_prompt
from _prompts.service.get_mongo_prompt import get_mongo_prompt
from config import OPENAI_API_KEY
from _constants.Model import Model
from _prompts.get_kkk_prompts import KkkPrompt
from _prompts.service.get_ref_prompt import get_ref_prompt
from utils.format_paragraphs import format_paragraphs
from utils.query_parser import parse_query
from utils.text_cleaner import comprehensive_text_clean


model_name: str = Model.GPT5_CHAT
min_length: int
max_length: int

client = OpenAI(api_key=OPENAI_API_KEY)


def kkk_gen(user_instructions: str, ref: str = "", category: str = "") -> str:
    """
    Returns:
        ìƒì„±ëœ ì›ê³  í…ìŠ¤íŠ¸ (str)

    Raises:
        RuntimeError: ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í•œ ê²½ìš° ë“±
        ValueError: API í‚¤ ë¯¸ì„¤ì • ë“±ì˜ í™˜ê²½ ì´ìŠˆ
        Exception: OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ë“± ê¸°íƒ€ ì˜ˆì™¸
    """

    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    parsed = parse_query(user_instructions)

    if category == "legalese":
        model_name = Model.GPT5
    else:
        model_name = Model.GPT5_CHAT

    if not parsed["keyword"]:
        raise ValueError("í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    if model_name == Model.GPT5_CHAT:
        [min_length, max_length] = [3000, 3200]
    else:
        [min_length, max_length] = [2400, 2600]

    default_prompt = KkkPrompt.kkk_prompt_gpt_5(
        keyword=parsed["keyword"],
        min_length=min_length,
        max_length=max_length,
        category=category,
    )
    mongo_data = get_mongo_prompt(category)
    ref_prompt = get_ref_prompt(ref)

    system = KkkPrompt.get_kkk_system_prompt_v2()

    user: str = (
        f"""

[ë¼ì´ë¸ŒëŸ¬ë¦¬ ë°ì´í„°]
{mongo_data}

[ì°¸ì¡°ì›ê³  ë°ì´í„°]
{ref_prompt}

ìœ„ ë°ì´í„°ë¥¼ í† ëŒ€ë¡œ ë¸”ë¡œê·¸ ë°”ì´ëŸ´ ë§ˆì¼€íŒ… ì›ê³ ë¥¼ ì‘ì„±í•´

[ì›ê³  ì‘ì„± ê·œì¹™]

{default_prompt}

{alticle_nat_prompt}

{article_flow_prompt}

---

[ìœ ì € ì¶”ê°€ ìš”ì²­]
{parsed.get('note', '')}

---
""".strip()
    )

    try:
        start_ts = time.time()
        is_ref = len(ref) != 0
        print(
            f"[GEN] service={'test-kkk'} | model={model_name} | category={category} | keyword={user_instructions} | is_ref={is_ref}"
        )
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": system,
                },
                {
                    "role": "user",
                    "content": user,
                },
            ],
        )

        usage = getattr(response, "usage", None)
        if usage is not None:
            in_tokens = getattr(usage, "prompt_tokens", None)
            out_tokens = getattr(usage, "completion_tokens", None)
            total_tokens = getattr(usage, "total_tokens", None)
            print(
                f"[ğŸ” Token Usage] "
                f"Prompt: {in_tokens:,}  |  "
                f"Completion: {out_tokens:,}  |  "
                f"Total: {total_tokens:,}"
            )
        choices = getattr(response, "choices", []) or []
        if not choices or not getattr(choices[0], "message", None):
            raise RuntimeError("ëª¨ë¸ì´ ìœ íš¨í•œ choices/messageë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        text: str = (choices[0].message.content or "").strip()
        if not text:
            raise RuntimeError("ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

        text = format_paragraphs(text)
        text = comprehensive_text_clean(text)

        length_no_space = len(re.sub(r"\s+", "", text))
        elapsed = time.time() - start_ts
        print(f"ì›ê³  ê¸¸ì´ ì²´í¬: {length_no_space}")
        print(f"ì›ê³  ì†Œìš”ì‹œê°„: {elapsed:.2f}s")
        print("ì›ê³ ì‘ì„± ì™„ë£Œ")

        return text

    except Exception as e:
        raise
