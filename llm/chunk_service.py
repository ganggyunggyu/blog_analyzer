from __future__ import annotations
import re

from openai import OpenAI
from config import OPENAI_API_KEY
from _constants.Model import Model
from utils.query_parser import parse_query


model_name: str = Model.GPT5

client = OpenAI(api_key=OPENAI_API_KEY)


def chunk_gen(user_instructions: str, ref: str = "", category: str = "") -> str:
    """
    Returns:
        ìƒì„±ëœ ì›ê³  í…ìŠ¤íŠ¸ (str)

    Raises:
        RuntimeError: ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í•œ ê²½ìš° ë“±
        ValueError: API í‚¤ ë¯¸ì„¤ì • ë“±ì˜ í™˜ê²½ ì´ìŠˆ
        Exception: OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ë“± ê¸°íƒ€ ì˜ˆì™¸
    """

    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    print(f"Chunk Service {user_instructions}")
    parsed = parse_query(user_instructions)

    if not parsed["keyword"]:
        raise ValueError("í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    keyword = parsed["keyword"]

    user: str = (
        f"""

[ê°œìš”]
í•˜ë‹¨ì— ìˆëŠ” ì°¸ì¡°ì›ê³  í•œì¤„í•œì¤„ ì „ë¶€ ê¼¼ê¼¼íˆ ìª¼ê°  í›„ì— ì–´íˆ¬ë‚˜ ì´ìŒì„¸ë§Œ ì‚´ì§ ë°”ê¿”ì„œ ì™„ì „íˆ ìœ ì‚¬í•œ ëª¨ì–‘ìƒˆì˜ ì›ê³ ë¡œ ë‹¤ì‹œ ì¤˜
ì´ë ‡ê²Œ í•˜ë©´ ê¸€ì”¨ ê¸¸ì´ë„ ë‹¹ì—°íˆ ì°¸ì¡° ì›ê³ ë‘ ë¹„ìŠ·í•´ì•¼í•˜ê³  ê·¸ ì•ˆì— ìˆëŠ” í‘œí˜„ê°™ì€ê²ƒë„ ì „ë¶€ ë¹„ìŠ·í•˜ê² ì§€?

í•µì‹¬ í‚¤ì›Œë“œë¥¼ íŒŒì•…í•´ì„œ ê·¸ëŸ° ê²ƒë“¤ì˜ ê°œìˆ˜ë„ ìœ ì‚¬í•´ì•¼í•´

ê·¸ë¦¬ê³  ìŠ¤í† ë¦¬í…”ë§ ê°™ì€ ê²ƒë§Œ ì‚´ì§ ë³€í™”í•˜ëŠ”ê±°ì•¼
ì˜ˆë¥¼ ë“¤ì–´ 4ëª…ì´ ê°„ë‹¤ ê·¸ëŸ¬ë©´ 3ëª…
20ëŒ€ ì—¬ì„±ì´ë‹¤ ê·¸ëŸ¬ë©´ 30ëŒ€ ì—¬ì„± ì´ëŸ° ì‹ìœ¼ë¡œ

ê·¸ë¦¬ê³  í‘œí˜„ë„ ì—ì‹œë¥¼ ëª‡ê°œ ì¤„ê²Œ ì°¸ê³ í•´ 
ì˜ˆì‹œëŠ” ì°¸ê³ ë§Œ í•˜ê³  ëª¨ë“ ê±¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ë§ê³  ì°½ì˜ì ìœ¼ë¡œ ê¸€ì„ ë§Œë“¤ì–´ì¤˜ì•¼í•´

[ì´í–‰ ì‚¬ì•ˆ]

{{}} << ì´ëŸ° ë¶€ë¶„ì€ ë³€ìˆ˜ë‹ˆê¹Œ í•­ìƒ ë™ì¼í•˜ì§€ ì•Šê²Œ ì±„ì›Œë„£ì–´ì¤˜
- ë³€ìˆ˜ëŠ” ë‚´ê°€ ì¤€ ê²ƒ ë§ê³ ë„ ìƒí™©ì— ë”°ë¼ ì§ì ‘ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í•´ì•¼í•´
- í•˜ë‹¨ì— ì›ë³¸ê³¼ ë³€í™˜ë³¸ì€ ë‹¨ì§€ ì˜ˆì‹œì¼ ë¿ì´ë¼ ë‚´ê°€ ì¤€ ê²ƒë“¤ ì•ˆì—ì„œë§Œ í™œìš©í•´ì„œëŠ” ì•ˆë¼ ì–¸ì œë‚˜ ìœ ë™ì ìœ¼ë¡œ ì§ì ‘ ì°¾ì•„ì„œ ë³€í™˜í•´ì¤˜
- ë³€ìˆ˜ëŠ” ì›ê³ ì—ì„œëŠ” í‹°ê°€ ë‚˜ì„œëŠ” ì•ˆë¼ ê·¸ëƒ¥ ë‹¨ì–´ë¡œ ì‚¬ìš©í•´ì¤˜ ê·¸ëƒ¥ ê¸€ì¸ê±°ì•¼
- ì›ë³¸/ë³€í™˜ë³¸ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•´ì„œ ë§ˆì§€ë§‰ì— --- í•˜ê³  ì•„ë˜ì— ì ì–´ì¤˜

ì›ë³¸: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ê³¼ ë³µìš©ì‹œê°„ì€? ( ì•Œí‹°ì§€, ì´ˆì„ê³„, ê³ ìˆœë„ )
ë³€í™˜: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ ê·¸ë¦¬ê³  ë³µìš©ì‹œê°„ ( ì•Œí‹°ì§€, ì´ˆì„ê³„, ê³ ìˆœë„ )

ì›ë³¸: ì•ˆì‹¬í•˜ê³  ë¨¹ì„ ìˆ˜ ìˆê² ë”ë¼ê³ ìš”.
ë³€í™˜: ì•ˆì‹¬í•˜ê³  ë¨¹ì„ ìˆ˜ ìˆê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”.

ì›ë³¸: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ ê¸°ì¤€ê³¼ ë³µìš©ì‹œê°„ 
ë³€í™˜: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ì˜ ê¸°ì¤€ ê·¸ë¦¬ê³  ë³µìš©ì‹œê°„

ì›ë³¸: ã„±ì”¨
ë³€í™˜: {{A}}ì”¨

ì›ë³¸: ì €ëŠ” ì§‘ì´ ë‚¨ì–‘ì£¼ë¼ ì¸ì²œê³µí•­ ì½œíƒì‹œ ê°€ê²©ì´
ë³€í™˜: ì €ëŠ” {{ì¶œë°œì§€}}ê°€ {{ë™íƒ„ì´}}ë¼ ì¸ì²œê³µí•­ ì½œíƒì‹œ ê°€ê²©ì´

ì›ë³¸: ìƒˆë²½ ì¶œêµ­ì´ë‚˜ ëŠ¦ì€ ì…êµ­ì—ë„
ì›ë³¸: ìƒˆë²½ì— ì¶œêµ­ì„ í•˜ëŠ” ê²½ìš°ë‚˜ ëŠ¦ì€ ì‹œê°„ì— ì…êµ­í•˜ëŠ” ê²½ìš°ë¼ë„

ì¼ì •í•œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë” ê¹”ë”í•˜ê²Œ ë³€í˜•ì„ ì¤˜ë„ ê´œì°®ì•„

[ê¸ˆì§€ ì‚¬ì•ˆ]

ì´ëŸ° ë¸”ë¡œê·¸ ìš”ì†Œë“¤ì€ ë”°ë¼í•˜ì§€ì•Šì•„ë„ë¼ -> {{ì¬ìƒ
2

ì¢‹ì•„ìš”
0

00:28

ì ‘ê¸°/í´ê¸°}}, {{ğŸ“ì¸ì²œê³µí•­ íƒì‹œ ì˜ˆì•½ ë°”ë¡œê°€ê¸°ğŸ“

ì¸ì²œê³µí•­íƒì‹œì½œì„¼í„°
ì¸ì²œê³µí•­ ë§¤ì¼ ìš´í–‰ ì¼ë°˜/ëŒ€í˜•/ì½œë°´ ë°°ì°¨ 1666-8856 24ì‹œê°„ ì˜ˆì•½ ìƒë‹´

pf.kakao.com}}


    {keyword}
---
""".strip()
    )

    print(f"Chunk Service íŒŒì‹± ê²°ê³¼: {parsed}")

    try:
        print(
            f"Chunk GPT ìƒì„± ì‹œì‘ | keyword={user_instructions!r} | model={model_name}"
        )
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": "ë„ˆëŠ” ì›ê³ ë¥¼ ì²­í¬ë¡œ ìª¼ê°œì„œ ë‹¤ì‹œ ë§Œë“¤ì–´ì£¼ëŠ” ì „ë¬¸ê°€ì•¼",
                },
                {
                    "role": "user",
                    "content": user,
                },
            ],
        )

        usage = getattr(response, "usage", None)
        if usage is not None:
            in_tokens = getattr(usage, "prompt_tokens", None)
            out_tokens = getattr(usage, "completion_tokens", None)
            total_tokens = getattr(usage, "total_tokens", None)
            print(
                f"KKK Service tokens in={in_tokens}, out={out_tokens}, total={total_tokens}"
            )

        choices = getattr(response, "choices", []) or []
        if not choices or not getattr(choices[0], "message", None):
            raise RuntimeError("ëª¨ë¸ì´ ìœ íš¨í•œ choices/messageë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        text: str = (choices[0].message.content or "").strip()
        if not text:
            raise RuntimeError("ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

        length_no_space = len(re.sub(r"\s+", "", text))
        print(f"KKK {model_name} ë¬¸ì„œ ìƒì„± ì™„ë£Œ (ê³µë°± ì œì™¸ ê¸¸ì´: {length_no_space})")

        return text

    except Exception as e:
        print("KKK OpenAI í˜¸ì¶œ ì‹¤íŒ¨:", repr(e))
        raise
