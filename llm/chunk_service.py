from __future__ import annotations
import re

from openai import OpenAI
import time
from _prompts.get_kkk_prompts import KkkPrompt
from config import OPENAI_API_KEY
from _constants.Model import Model
from utils.format_paragraphs import format_paragraphs
from utils.query_parser import parse_query
from utils.text_cleaner import clean_multiple_spaces, clean_text_format


model_name: str = Model.GPT5

client = OpenAI(api_key=OPENAI_API_KEY)


def chunk_gen(user_instructions: str, ref: str = "", category: str = "") -> str:
    """
    Returns:
        ìƒì„±ëœ ì›ê³  í…ìŠ¤íŠ¸ (str)

    Raises:
        RuntimeError: ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í•œ ê²½ìš° ë“±
        ValueError: API í‚¤ ë¯¸ì„¤ì • ë“±ì˜ í™˜ê²½ ì´ìŠˆ
        Exception: OpenAI í˜¸ì¶œ ì‹¤íŒ¨ ë“± ê¸°íƒ€ ì˜ˆì™¸
    """

    if not OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")

    # ë””ë²„ê·¸ ì¶œë ¥ ì œê±°
    parsed = parse_query(user_instructions)

    sys = KkkPrompt.get_kkk_system_prompt_v2()

    if not parsed["keyword"]:
        raise ValueError("í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

    keyword = parsed["keyword"]

    user: str = (
        f"""

[ê°œìš”]

{keyword}

ìœ„ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì›ê³ ë¥¼ ì‘ì„±í•´ì¤˜

í•˜ë‹¨ì— ìˆëŠ” ì°¸ì¡°ì›ê³  í•œì¤„í•œì¤„ ì „ë¶€ ê¼¼ê¼¼íˆ ìª¼ê°  í›„ì— ì–´íˆ¬ë‚˜ ì´ìŒì„¸ë§Œ ì‚´ì§ ë°”ê¿”ì„œ ì™„ì „íˆ ìœ ì‚¬í•œ ëª¨ì–‘ìƒˆì˜ ì›ê³ ë¡œ ë‹¤ì‹œ ì¤˜
ì´ë ‡ê²Œ í•˜ë©´ ê¸€ì”¨ ê¸¸ì´ë„ ë‹¹ì—°íˆ ì°¸ì¡° ì›ê³ ë‘ ë¹„ìŠ·í•´ì•¼í•˜ê³  ê·¸ ì•ˆì— ìˆëŠ” í‘œí˜„ê°™ì€ê²ƒë„ ì „ë¶€ ë¹„ìŠ·í•˜ê² ì§€?

min_length: int | None = 3000,
max_length: int | None = 3200,

ë¬¸ì ê¸¸ì´ëŠ” ìœ„ ê³µë°±ì œì™¸ ê¸¸ì´ ì‚¬ì´ë¡œ ì§„í–‰í•´ì¤˜

3000ë‹¨ì–´ ì´ìƒ

í•µì‹¬ í‚¤ì›Œë“œë¥¼ íŒŒì•…í•´ì„œ ê·¸ëŸ° ê²ƒë“¤ì˜ ê°œìˆ˜ë„ ìœ ì‚¬í•´ì•¼í•´
í˜•íƒœì†Œ ê°œìˆ˜ì™€ í† í°ì˜ ê°œìˆ˜ë„ ìœ ì‚¬í•´ì•¼í•´
### ## # ë“±ë“±ì„ í¬í•¨í•œ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•ì€ ì ˆëŒ€ ê¸ˆì§€ì•¼

ê·¸ë¦¬ê³  ìŠ¤í† ë¦¬í…”ë§ ê°™ì€ ê²ƒë§Œ ì‚´ì§ ë³€í™”í•˜ëŠ”ê±°ì•¼
ì˜ˆë¥¼ ë“¤ì–´ 4ëª…ì´ ê°„ë‹¤ ê·¸ëŸ¬ë©´ 3ëª…
20ëŒ€ ì—¬ì„±ì´ë‹¤ ê·¸ëŸ¬ë©´ 30ëŒ€ ì—¬ì„± ì´ëŸ° ì‹ìœ¼ë¡œ
ê³ ë“±í•™ìƒ ìœ„íƒ êµìœ¡ ê³¼ì •ì´ë¼ë©´ ì„±ì¸ë°˜ ì„±ì¸ êµìœ¡ê³¼ì • ì´ëŸ° ì‹ìœ¼ë¡œ

ì•„ë˜ ì‚¬í•­ë“¤ì„ ë¬´ì‹œí•´ì„œë¼ë„ ì ˆëŒ€ ë‘ ì›ê³ ì˜ ìœ ì‚¬ë„ ìì¹´ë“œê°€ 50%ì´ìƒì´ ë˜ì–´ì•¼í•´

êµìœ¡ì— ê´€ë ¨ëœ ê±°ë¼ë©´ í•´ë‹¹ êµìœ¡ê¸°ê´€ì—ì„œ ë°°ìš¸ë§Œí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë³€ê²½í•´ì„œ í•´ì¤˜

ê·¸ë¦¬ê³  í‘œí˜„ë„ ì—ì‹œë¥¼ ëª‡ê°œ ì¤„ê²Œ ì°¸ê³ í•´ 
ì˜ˆì‹œëŠ” ì°¸ê³ ë§Œ í•˜ê³  ëª¨ë“ ê±¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì§€ë§ê³  ì°½ì˜ì ìœ¼ë¡œ ê¸€ì„ ë§Œë“¤ì–´ì¤˜ì•¼í•´

ë§íˆ¬ë„ í™”ìì— ë§ê²Œ í•´ì£¼ë©´ ì¢‹ì•„

ê° ë¬¸ë‹¨ë§ˆë‹¤ ë¶€ì œëŠ” í•„ìˆ˜ì•¼

[ì´í–‰ ì‚¬ì•ˆ]

{{}} << ì´ëŸ° ë¶€ë¶„ì€ ë³€ìˆ˜ë‹ˆê¹Œ í•­ìƒ ë™ì¼í•˜ì§€ ì•Šê²Œ ì±„ì›Œë„£ì–´ì¤˜
- ë³€ìˆ˜ëŠ” ë‚´ê°€ ì¤€ ê²ƒ ë§ê³ ë„ ìƒí™©ì— ë”°ë¼ ì§ì ‘ ë§Œë“¤ì–´ì„œ ì‚¬ìš©í•´ì•¼í•´
- í•˜ë‹¨ì— ì›ë³¸ê³¼ ë³€í™˜ë³¸ì€ ë‹¨ì§€ ì˜ˆì‹œì¼ ë¿ì´ë¼ ë‚´ê°€ ì¤€ ê²ƒë“¤ ì•ˆì—ì„œë§Œ í™œìš©í•´ì„œëŠ” ì•ˆë¼ ì–¸ì œë‚˜ ìœ ë™ì ìœ¼ë¡œ ì§ì ‘ ì°¾ì•„ì„œ ë³€í™˜í•´ì¤˜
- ë³€ìˆ˜ëŠ” ì›ê³ ì—ì„œëŠ” í‹°ê°€ ë‚˜ì„œëŠ” ì•ˆë¼ ê·¸ëƒ¥ ë‹¨ì–´ë¡œ ì‚¬ìš©í•´ì¤˜ ê·¸ëƒ¥ ê¸€ì¸ê±°ì•¼
- ì›ë³¸/ë³€í™˜ë³¸ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•´ì„œ ë§ˆì§€ë§‰ì— --- í•˜ê³  ì•„ë˜ì— ì ì–´ì¤˜
- í•µì‹¬ì€ ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë†’ìœ¼ë©´ ì‹ ê³  ë‹¹í•˜ê±°ë‚˜ ê·¸ëŸ´ ìˆ˜ ìˆìœ¼ë‹ˆ ìµœëŒ€í•œ í•µì‹¬ ë‚´ìš©ê³¼ íë¦„ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ëŠ” ê°€ì ¸ì˜¤ë©´ì„œ ìœ ì‚¬ë„ëŠ” ë‚®ì•„ì•¼í•´
- ë¶€ì œë„ ì˜ë¯¸ëŠ” ê°™ì§€ë§Œ ì¢€ ìˆ˜ì •í•´ì£¼ë©´ ì¡°ì„ë“¯
- í•µì‹¬ í‚¤ì›Œë“œì˜ ë¹ˆë„ëŠ” ë…¸ì¶œìœ¨ê³¼ ì—°ê´€ ë˜ì–´ìˆì–´ ì‚¬ì´ì— , ê°™ì€ê±¸ ë„£ì–´ì„œëŠ” ì•ˆë¼
    - ìœ„ê³ ë¹„, ì•Œì•½ X ìœ„ê³ ë¹„ ì•Œì•½ O

ì›ë³¸: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ê³¼ ë³µìš©ì‹œê°„ì€? ( ì•Œí‹°ì§€, ì´ˆì„ê³„, ê³ ìˆœë„ )
ë³€í™˜: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ ê·¸ë¦¬ê³  ë³µìš©ì‹œê°„ ( ì•Œí‹°ì§€, ì´ˆì„ê³„, ê³ ìˆœë„ )

ì›ë³¸: ì•ˆì‹¬í•˜ê³  ë¨¹ì„ ìˆ˜ ìˆê² ë”ë¼ê³ ìš”.
ë³€í™˜: ì•ˆì‹¬í•˜ê³  ë¨¹ì„ ìˆ˜ ìˆê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ë”ë¼êµ¬ìš”.

ì›ë³¸: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ ê¸°ì¤€ê³¼ ë³µìš©ì‹œê°„ 
ë³€í™˜: ì˜¤ë©”ê°€3 í•˜ë£¨ì„­ì·¨ëŸ‰ì˜ ê¸°ì¤€ ê·¸ë¦¬ê³  ë³µìš©ì‹œê°„

ì›ë³¸: ã„±ì”¨
ë³€í™˜: {{A}}ì”¨

ì›ë³¸: ì €ëŠ” ì§‘ì´ ë‚¨ì–‘ì£¼ë¼ ì¸ì²œê³µí•­ ì½œíƒì‹œ ê°€ê²©ì´
ë³€í™˜: ì €ëŠ” {{ì¶œë°œì§€}}ê°€ {{ë™íƒ„ì´}}ë¼ ì¸ì²œê³µí•­ ì½œíƒì‹œ ê°€ê²©ì´

ì›ë³¸: ìƒˆë²½ ì¶œêµ­ì´ë‚˜ ëŠ¦ì€ ì…êµ­ì—ë„
ì›ë³¸: ìƒˆë²½ì— ì¶œêµ­ì„ í•˜ëŠ” ê²½ìš°ë‚˜ ëŠ¦ì€ ì‹œê°„ì— ì…êµ­í•˜ëŠ” ê²½ìš°ë¼ë„

ì¼ì •í•œ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë” ê¹”ë”í•˜ê²Œ ë³€í˜•ì„ ì¤˜ë„ ê´œì°®ì•„

ì—…ì²´ëª…ì€ ë³„ë„ ìš”ì²­ì´ ì—†ë‹¤ë©´ ë„£ì§€ ë§ê³  ì‘ì„±í•´ì¤˜

- í•œ ì¤„ì€ 50ìë¥¼ ë„˜ê¸°ì§€ ì•Šë„ë¡ ì‘ì„±  
- í•œ ì¤„ì€ ê°€ê¸‰ì  ì•½ 45ì ì´í›„ ìì—°ìŠ¤ëŸ½ê²Œ ì¤„ë°”ê¿ˆ  
- ì¤„ë°”ê¿ˆ ì‹œ ì´ìŒì„¸(ê·¸ë˜ì„œ, ê·¸ë¦¬ê³ , ë˜í•œ, í•˜ì§€ë§Œ ë“±)ë¥¼ í™œìš©í•˜ì—¬ ë¬¸ì¥ì´ ë§¤ë„ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•¨  
- `,` ë•Œë¬¸ì— ì¤„ë°”ê¿ˆí•˜ì§€ ì•ŠëŠ”ë‹¤  
- ë¶€ì œ í•˜ë‹¨ì€ ì¤„ë°”ê¿ˆ ë‘ ë²ˆ  
- 2~3ì¤„ë§ˆë‹¤ ì¤„ë°”ê¿ˆ  
- í•œ ë¬¸ë‹¨ì€ 3~5ì¤„ ìœ ì§€  
- ì§§ì€ ë¬¸ì¥ì„ ë§ˆêµ¬ ëŠì§€ ì•Šê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¦¬ë“¬ìœ¼ë¡œ ì‘ì„±  
- ëª¨ë“  í•œ ì¤„ì€ ì¼ì •í•œ ê¸¸ì´ë¡œ ì¶œë ¥í•˜ë©°, ìš°ì¸¡ ê³µë°± ê¸ˆì§€  
- ë¬¸ì¥ì˜ ëë§ºìŒì€ ë‹¤ì–‘í•˜ê²Œ:
  - ~ìš”, ~ë´¤ë‹µë‹ˆë‹¤, ~í–ˆì£ , ~ê·¸ë¬ì—ˆì£ , ~ìˆì—ˆì£ , ~ê·¸ë¬ì–´ìš”, ~êµ¬ìš”, ~ë‹µë‹ˆë‹¤ ë“±  
- ê°™ì€ ì–´ë¯¸ê°€ 3íšŒ ì´ìƒ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ ì¡°ì •  

[ê¸ˆì§€ ì‚¬ì•ˆ]

ê¸¸ì´ëŠ” ê¸°ì¡´ì˜ ê¸€ë³´ë‹¤ ì§§ì•„ì„œëŠ” ì•ˆë¼

ì´ëŸ° ë¸”ë¡œê·¸ ìš”ì†Œë“¤ì€ ë”°ë¼í•˜ì§€ì•Šì•„ë„ë¼ -> {{ì¬ìƒ
2

ì¢‹ì•„ìš”
0

00:28

ì ‘ê¸°/í´ê¸°}}, {{ğŸ“ì¸ì²œê³µí•­ íƒì‹œ ì˜ˆì•½ ë°”ë¡œê°€ê¸°ğŸ“

ì¸ì²œê³µí•­íƒì‹œì½œì„¼í„°
ì¸ì²œê³µí•­ ë§¤ì¼ ìš´í–‰ ì¼ë°˜/ëŒ€í˜•/ì½œë°´ ë°°ì°¨ 1666-8856 24ì‹œê°„ ì˜ˆì•½ ìƒë‹´

pf.kakao.com}}


    {ref}


---

[ì¶”ê°€ ì´í–‰ì‚¬í•­]
- í•„ìˆ˜ë¡œ ì´í–‰ë˜ì–´ì•¼í•´
- ì—†ë‹¤ë©´ ìœ„ ì‚¬í•­ë§Œìœ¼ë¡œ ì›ê³  ì‘ì„±

{parsed['note']}
---
""".strip()
    )

    # ë””ë²„ê·¸ ì¶œë ¥ ì œê±°

    try:
        start_ts = time.time()
        print("ì›ê³ ì‘ì„± ì‹œì‘")
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {
                    "role": "system",
                    "content": sys,
                },
                {
                    "role": "user",
                    "content": user,
                },
            ],
        )

        usage = getattr(response, "usage", None)
        if usage is not None:
            in_tokens = getattr(usage, "prompt_tokens", None)
            out_tokens = getattr(usage, "completion_tokens", None)
            total_tokens = getattr(usage, "total_tokens", None)
            # í† í° ì‚¬ìš©ëŸ‰ ë¡œê¹… ì œê±°

        choices = getattr(response, "choices", []) or []
        if not choices or not getattr(choices[0], "message", None):
            raise RuntimeError("ëª¨ë¸ì´ ìœ íš¨í•œ choices/messageë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        text: str = (choices[0].message.content or "").strip()
        if not text:
            raise RuntimeError("ëª¨ë¸ì´ ë¹ˆ ì‘ë‹µì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤.")

        if model_name != Model.GPT5:
            text = format_paragraphs(text)

        text = clean_text_format(text)

        length_no_space = len(re.sub(r"\s+", "", text))
        elapsed = time.time() - start_ts
        print(f"ì›ê³  ê¸¸ì´ ì²´í¬: {length_no_space}")
        print(f"ì›ê³  ì†Œìš”ì‹œê°„: {elapsed:.2f}s")
        print("ì›ê³ ì‘ì„± ì™„ë£Œ")

        return text

    except Exception as e:
        raise
